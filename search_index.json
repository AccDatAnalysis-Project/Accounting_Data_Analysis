[["index.html", "会計情報のデータ分析 まえがき", " 会計情報のデータ分析 北田智久・濵村純平・井上謙仁 編 まえがき 近年，会計データによる経営分析は，単なる比率の分析だけでなく，統計学や計量経済学の考え方を取り入れて発展してきた。 本書は，このような統計的な技法を含めた会計データ分析の入門書である。 このような分析に必要となるのは， 会計学の知識 統計学の知識 統計ソフトの知識 である。本書では，日商簿記検定の3級程度の知識は持っているが，統計学や統計ソフトの知識はほとんどないという学部生を対象として執筆された。 入門書だが，データの整形作業などのデータ分析に必要な工程は最低限網羅している。 なお，本書には実際にコードを実行するためのweb付録（https://accdatanalysis-project.github.io/Accounting_Data_Analysis/）がついているので，ぜひ活用してほしい。 本書の演習を通じて，会計データ分析の世界へ第一歩を踏み出してほしい。 付録に関しては要検討。 "],["01-会計情報データを統計分析.html", "Chapter 1 会計情報を統計分析する：必要性と困難性 1.1 「会計情報を統計分析する」とは？ 1.2 実証的な会計研究からの示唆：「コスト変動研究」と「利益調整研究」 1.3 企業内部で会計情報の統計分析を実施「できない」理由", " Chapter 1 会計情報を統計分析する：必要性と困難性 この教科書は，会計情報を統計分析し，企業内部のマネジャーが経営上の様々な意思決定に役立てていくための諸技法を解説している。 事前の知識としては，簿記3級以上の仕訳の知識，ビジネス会計検定3級以上の財務諸表の知識を前提としている。 また，統計学についても統計検定3級以上の知識があると望ましいが，本書の最低限の解説で，分析自体は実行可能だろう。 1.1 「会計情報を統計分析する」とは？ ビジネスに役立つ会計情報分析といえば，これまでROA（Return on Assets: 総資産利益率）やROE（Return on Equity: 自己資本利益率）のような，比率の計算を主とする，いわゆる財務諸表分析とよばれる手法が中心だった。 これら比率の計算は，あたかも人体の問題を血圧や血中の各種バイタル指標が早期に警告してくれるかのように，企業の問題点を警告してくれる重要なものである。 この計算の意義は，近年でも依然として重要である。 次の表1.1は，ビジネス会計検定3級で触れられている指標を抜粋した一般的な指標の例である。 Table 1.1: 代表的な財務分析の指標 指標 定義 【安全性の指標】 流動比率 (流動資産/流動負債)×100 (%) 当座比率 ((流動資産-棚卸資産)/流動負債)×100 (%) 自己資本比率 (純資産/負債純資産合計)×100 (%) 【収益性の指標】 総資本経常利益率(ROA) (経常利益/負債純資産合計)×100 (%) 自己資本利益率(ROE) (当期純利益/自己資本)×100 (%) 売上高経常利益率 (経常利益/売上高)×100 (%) 総資本回転率 売上高/負債純資産合計 (回転) これらの指標は，経営におけるリスクとリターンという，最も根源的な2つの要因について，重要な示唆を与えてくれる。 そのため，経営分析指標は長い期間に渡って企業経営にもちいられてきた1。 しかし，近年の統計分析理論や分析用機器の性能の発達は，単なる比率分析を超えた分析の可能性を示唆する。 具体的には，会計研究においては，「コスト変動研究」と「利益調整研究」という2つの実証的な研究領域が，企業経営にも役立つだろう。 1.2 実証的な会計研究からの示唆：「コスト変動研究」と「利益調整研究」 この教科書では，無料の統計ソフトであるRを利用した分析を紹介するが，特に重視するのが「回帰分析」とよばれる分析技法である。 例えば，CVP分析でよくみる次のモデルを考えてみよう。 \\[\\begin{equation} \\mbox{コスト}=\\beta_0 + \\beta_1 \\times \\mbox{売上高} + \\varepsilon. \\label{eq:ak1} \\end{equation}\\] もし，コストと売上高の一定期間のデータがあれば，\\(\\beta_0\\)（固定費部分）と\\(\\beta_1\\)（変動費率部分）を回帰分析で推定できる。 また，売上高で説明しきれないコストは，残差とよばれる\\(\\varepsilon\\)（イプシロン）部分で表現されている。 この回帰分析を利用して，コスト変動研究と利益調整研究は展開されている。 まず，コスト変動研究は，先程の()式を様々に展開して，コスト変動のより深い理解を探る研究が進展した。 たとえば，活動基準原価計算（Activity-based costing; ABC）は，生産数量以外のコスト・ドライバーを想定した原価計算である。 その場合，コストを製造間接費とし，生産数量の代理変数たる売上高の影響\\(\\beta_1\\)以外にも，他のコスト・ドライバー（\\(\\beta_2 \\times\\)ロットサイズとか\\(\\beta_3 \\times\\)製造現場の面積など）を含んで，回帰分析を実行する。 そうすることで，単一のコスト・ドライバーを想定する既存の原価計算における配賦の歪みの問題点を明らかにした研究がある2。 また，販売費及び一般管理費（以下，販管費と略す）を対象として，売上高の増加時と減少時で非対称的な変動がみられることを観察した研究も進展した。具体的には，売上高が上昇した際の販管費の上昇分に対して，売上高が減少した際の販管費はそれほど減少しない，「コストの下方硬直性」という現象の発見であるがそうである(M. C. Anderson, Banker, and Janakiraman 2003)。 これは，販管費が，単なる当期のコストという性質にとどまらず，ある程度は無形資産への支出のような意味合いを持つ可能性を示唆したともいえる。 ざっくりといえば，コスト変動研究が\\(\\beta_1\\)などのコスト変動の係数に着目した研究群だったのに対し，利益調整研究は説明されない\\(\\varepsilon\\)に着目した研究群である。 たとえば，キャッシュは，当期純利益とかなり相関していると考えられるが，利益によって予測されるキャッシュと実際のキャッシュの乖離が大きい場合，なんらかの会計的な利益の操作が行われたのではないかと推測するのである3。 実際，赤字を回避したり，目標利益を達成したりする際に，キャッシュで説明できない利益が増加するという。 具体的には，減価償却費の償却方法を変更したり，貸倒引当金の見積り金額を変更したりするなどの方法が取られるようだ。 また，過剰在庫を積み上げたり，広告宣伝費を過度に減少させたりといった「実体的な」利益調整も存在するという4。 これも同様に説明されない残差に着目した研究群だが，現在までには，「押し込み営業」，「過剰在庫」，「自由裁量費の削減」などが統計的にある程度は識別可能な状況のようだ。 このような研究は，資本市場のアナリストだけではなく，企業内部のマネジャーにも重要な示唆を持つ。 というのも，コスト変動研究の成果は，予算作成のための見積財務諸表作成に直接的に貢献するし，利益調整研究の成果は，部門業績評価の際に直接的に貢献すると想定されるからである。 1.3 企業内部で会計情報の統計分析を実施「できない」理由 このような20世紀最後の10年間における会計情報の統計的分析技法の飛躍的な向上にもかかわらず，多くの企業ではこのような分析が普及することはなかった。 それはなぜだろうか。 これについては，21世紀以降の経営分析・管理会計論の代表的な研究者であるクリストファー・イットナーとデイビッド・ラーカーが，『戦略をコントロールする』という書籍の中に掲載した論文「戦略的測定から戦略的データ分析へ」の中で議論している(Ittner and Larcker 2005)。 彼らは，経営分析を計画策定やマネジメントのような業績測定システムに反映させることについての重要な論点を提供した。 多くのアメリカの企業が経営分析を業績測定システムの一環として実施していないことを次のように表現している（邦訳p. 118）。 …これらのメカニズムをうまく用いることが業績測定システムの成功と関連しており，財務業績を改善するということが次々と明らかにされているにもかかわらず…(中略)…，いくつかのサーベイ調査では，戦略的業績測定システムを利用する多くの企業がこうした分析を行わないことが示唆されており，これらの利用と効果を促進する要因あるいは阻害する要因に関して重要な問題が提起されている。 ここで引用した箇所は，現在の経営分析の企業での利用状況を簡潔に表しており示唆的である。 というのも，戦略的業績測定システムを利用している企業が多い，ということはすでに分析対象となるデータは企業内にすでに蓄積されていることを意味しているからである。 多くの企業では，新しくコストをかけることなく「今そこにあるデータ」を分析することで，より効率的な計画設定やマネジメントを実施できることになる。 そして，イットナーらの大規模なサーベイ調査（郵送アンケート調査のこと），および60社以上の大規模フィールドスタディの結果，特に次の3点を通じて，競争優位に良い影響を及ぼすと指摘した。 彼らが指摘した経営分析の機能の1つ目は，「戦略的前提の伝達の促進」である。 これは，分析結果そのものが部門間・階層間の対話を促進するということである。 2つ目は，「戦略的バリュードライバーの特定」である。自社の価値を増加させる要因をバリュードライバーとして特定でき，結果として3つ目の影響である「資源の有効利用」に結びつく。 つまり，企業の限られた資源をそのドライバーに集中できる。 もっとも，この3つの影響はいずれも戦略構築というよりは計画段階に偏っていることに注意が必要だろう。 戦略的前提の伝達の促進とは，すでに戦略的前提がなければ実施されないし，バリュードライバーや資源の利用方法には無数の選択肢があるものの，それを絞り込み方向性を示すものはやはり前提としての戦略だからである。 では，なぜ，多くの企業が会計情報の統計的分析を行わないのだろうか。 イットナーらは「なぜ多くの企業にとって戦略的業績指標と経済的な成果との結びつきを明らかにすることがきわめて困難になるのか」(邦訳p.129)と問いかけている。 論文後半で提示されるこの問いに対する答えは，(1)指標の不適切さ，(2)情報システムの問題，(3)データの不整合，(4)組織的な情報共有の欠如，(5)調整されていない分析，(6)結果の懸念，(7)組織の信念，と多岐にわたる。 (1)指標の不適切さ，(2)情報システムの問題，(3)データの不整合の3つはいずれも技術的な問題である。 そもそもの会計情報の選択が不適切だったり（(1)指標の不適切さ），組織内部に蓄積された適切な情報の存在そのものを分析者が認識できなかったり（(2)情報システムの問題），部門間で指標が異なっても同名称でよばれたりその逆の問題もある（(3)データの不整合性）。 (4)組織的な情報共有の欠如，(5)調整されていない分析，(6)結果の懸念，(7)組織の信念の4つは組織的な障害である。 部門間の壁が厚く情報には縄張りがあると，効果的な分析は困難となることは容易に想像が出来るだろう（(4)組織的な情報共有の欠如）。 また，経理部門が行った財務分析，人事部門が行った業績評価分析，品質管理・保証部門が行った品質分析などは，統合されてこそ威力を発揮するにもかかわらず，日々それぞれの部門に与えられた仕事をこなすのに精一杯で統合した分析を行おうという動機をほとんど持ちえないという問題もある（(5)調整されていない分析）。 そして，分析結果が既存の取り組みの不毛さを指摘することがありえるが，これは担当者にとっては暴かれたくなかった事実かもしれない。 このようなことが予想されるとしたら，事前に担当者は分析を妨害してくるかもしれない（(6)結果の懸念）。 あるいは，過去からの環境変化のためにその信念が陳腐化しているにもかかわらず，過去の経営者の直観と経験を強く信奉したいあまり，分析を拒否するということもある（(7)組織の信念）。 このような問題を解決するためには，まず会計情報の統計的分析が有効なことを理解する必要がある。 本書を読んで，会計情報の統計的分析の有用性を理解したら，このような組織的問題を克服し，自社に以下の章で紹介する諸分析を導入してもらいたい。 本書の構成は一般的なデータサイエンスのプロセスにのっとっており，次のとおりである。 まず，第2章ではデータの取得について解説する。自社内の情報を利用する場合もあれば，公開財務データを利用する場合もあるだろう。 企業内部のデータならばERP(Enterprise Resource Planning)などを利用して獲得できるが，外部データを効率的に獲得する方法は学習する必要があるだろう。 第3章から第4章までは分析ツールであるRおよびRstudioのインストールから，データを分析可能にするための前処理について学習する。 第5章では分析に必要なデータの視覚化について学習し，第6章から第7章までは実際に会計データを分析するプロセスを学習する。 経営分析の発達史については，例えば， 國部 (1994)『アメリカ経営分析発達史』（白桃書房）が参考になる。↩︎ たとえば， Banker, Potter, and Schroeder (1995) や S. W. Anderson and Sedatole (2012) などが参考になる。↩︎ これは Jones (1991) の研究が出発点となっている。↩︎ 詳細は Roychowdhury (2006) を参照せよ。↩︎ "],["02-会計データへのアクセス.html", "Chapter 2 会計データへのアクセス 2.1 会計データを入手し，整理する 2.2 EDINETの使い方 2.3 整然データとは", " Chapter 2 会計データへのアクセス &lt;学習目標&gt; ・会計データを入手できる ・整然データを構築できる 【応用例】 なし 【関連する会計研究】 Wickham, H. (2014) “Tidy Data,” Journal of Statistical Software Vol. 59, No. 10, pp. 1–23. 2.1 会計データを入手し，整理する 会計データを分析するには，何よりもまず会計データを入手する必要がある。 総資産や売上高，あるいは純利益のデータが手元にないと，分析をはじめることすらできない。 学術的研究では，「NEEDS-FinancialQUEST」や「eol」のようなデータベースから，会計データを入手して分析が行われている。 しかし，これらのデータベースは有料である。大学でこれらのデータベースが利用可能でなければ，卒業論文などで利用することは難しい。 もっと手軽にデータを入手する方法はないだろうか。 そこで，本章では，「EDINET」から会計データを無料で，しかもインターネットから簡単に入手する方法について紹介する5。 さらに，入手した会計データは，Rに読み込まれ，分析が実施されることになる。 ここで注意をしなければならないのが，収集されたデータがRで読み取りやすい形式になっているかということである。 もし，Rで操作しにくい形式であるならば，効率的な分析が不可能となってしまう。では，どのようなデータの形式が望ましいのだろうか。 したがって，本章では，「整然データ」についても学習することにする。 整然データは，Rなどの統計ソフトで操作のしやすいデータ構造である。整然データは効率的な分析を可能としてくれる。 2.2 EDINETの使い方 まず，各企業の会計データを入手してみよう。 会計データを用いた分析では，各企業が開示する有価証券報告書に記載されている財務数値を用いる。 そのため，会計データの取得には，有価証券報告書を1社ずつ入手し，そこから必要なデータを手作業で収集する事になる。 有価証券報告書は各企業のウェブページの「IR情報」から入手できることが多い。 ただし，複数企業のデータが欲しい場合には，企業のページに1社ずつアクセスして，1社ずつ有価証券報告書を収集する必要がある。 企業のウェブページは，企業ごとに体裁が異なっているため，有価証券報告書を各社ごとに探すという手間がかかってしまう。 もっと手軽に有価証券報告書を入手できる方法はないのだろうか。 そこで利用されるのが，「EDINET」である6。 EDINETを利用すれば，企業名を検索するだけで，有価証券報告書を閲覧することができる。 EDINETでも1社ずつ検索する必要はある。しかし，有価証券報告書をいちいち探さなくていい点，収集作業が断然楽になるだろう。 まず，検索サイトで「EDINET」と検索するか，「http://disclosure.edinet-fsa.go.jp/」にアクセスする。すると，図2.1のようなウェブページが表示される。 Figure 2.1: EDINETのトップページ 今回は「川崎重工業」に興味を持ったとし，川崎重工業の有価証券報告書を入手してみよう。まず，「書類検索」をクリックする。 すると，図2.2のページが表示される。 Figure 2.2: 検索画面 次に，このページの「書類提出者／有価証券発行者／ファンド情報を指定する」の欄の「提出社／発行者／ファンド」に「川崎重工業」と入力する。 また，会計データ分析では，基本的に複数年の有価証券報告書が必要である。そのために，「決算期／提出期間を指定する」の欄を展開し，そこの「提出期間」を「過去1年」から「全期間」に指定する必要がある。これで，EDINETに収録されている最大期間の有価証券報告書が検索できる。 「検索」のボタンを押すと，図2.3の検索結果が表示される。 「有価証券報告書」の行の「PDF」のアイコンをクリックすると，当該年度の有価証券報告書がPDFファイルの形式でダウンロードできる。 こうして，ダウンロードされた有価証券報告書を閲覧し，必要な財務数値を収集することになる7。 Figure 2.3: 検索結果 2.3 整然データとは 有価証券報告書から取得した財務数値は，一定のデータの形式に並べることになる。 データの形式はさまざま考えられる。 ここでポイントとなるのが，ここで構築されたデータはRで用いられるということだ。 すなわち，Rで扱いやすい形式のデータを構築する必要が出てくる。 では，データはどう並べるのがRでの分析に利用しやすいのだろうか。 ここで登場するのが，「整然データ」である。 整然データとは， Wickham (2014) で提唱されたデータ構造のことである。 Rなどの統計ソフトで分析するためには，整然データのルールにしたがってデータを並べることが重要となる。 Wickham (2014) によると，整然データを構築するためには，以下の3つの規則を満たす必要がある8。 それぞれの変数は，自身の列を有していないといけない。 それぞれの観測は，自身の行を有していないといけない。 それぞれの値は，自身のセルを有していないといけない。 では，具体的に，整然データの構造をみていこう。 ここでは，川崎重工業，三菱重工業，および住友重機械工業の売上高を2016年度から2018年度までの3年ずつ，合計で9企業年分入手したとする9。 その際，図2.4にデータをまとめたとしよう。 このような表はよくみるはずだ。 ここでは，行に企業名を並べ，列に年度を並べて，それぞれの行列に対応するセルに売上高が配置されている10。 この表は，企業と年度の対応があるため，我々人間にとっては確認がしやすい。 Figure 2.4: 雑然データの例 しかし，図2.4の形式は，上記の規則3以外守られていないため，整然データとはいえない。 このような整然データでない構造のデータは「雑然データ（messy data）」とよばれる。 雑然データは統計ソフトでは扱いにくい形式であり，分析に使用するのは好ましくない。 図2.4を整然データに並べ替えると，図2.5のようになる。なぜ，統計ソフトで扱う場合に雑然データではダメなのだろうか。規則を1つずつ確認することでみていこう11。 Figure 2.5: 整然データの例 まず，規則1の「それぞれの変数は，自身の列を有していないといけない」である。 変数とは，「企業名」「年度」「売上高」のようなデータを指す。 雑然データを見てみよう。ここで，これら変数は，図2.6のように企業名が列，年度が行，売上高にいたっては行列に並んでいる。 変数がバラバラに並んでいると，統計ソフトで変数を指定するとき，変数ごとに指定の方法がバラバラになり，コードを書くのがとても大変になる。 Figure 2.6: 規則1の例：雑然データ そこで，整然データの規則1が有効になる。図2.7のように，変数は列に並べる。 こうすることで，ソフト上では，列だけを指定することで変数を取り出すことができる。コードを書くのが楽になるのだ。 Figure 2.7: 規則1の例：整然データ 次に，規則2「それぞれの観測は，自身の行を有していないといけない」である。 観測は「川崎重工業の2018年度」のようにある観測された対象を示す。 ここで，川崎重工業の2018年度の売上高を確認してみよう。図2.8のように，行と列がそれぞれバラバラに位置されていることがわかる。 Figure 2.8: 規則2の例：雑然データ 統計ソフトに同じことをさせると，1つの観測を抜き出すのに，3箇所の行列の指定をしなければならない。 これは大変なので，図2.9のように，1つの観測値は1行に並ぶようにする。 これで，ソフト上で行だけを指定すれば，観測値を取り出すことができる。 Figure 2.9: 規則2の例：整然データ 最後に，規則3「それぞれの値は，独自のセルを有していないといけない」である。 値は「川崎重工業」や「3,914,018」のように観測された企業名や売上高などの内容そのものを指す。 ここで，川崎重工業の2016年の売上高が修正されたとしよう。 これを反映したのが図2.10であり，下の数値が修正された売上高である。 図2.10では，1つのセルに売上高が2つ入っている。 このように1つのセルにデータが2つ入っていると，セルを指定した際，売上高が2つ取り出されてしまう。 なので，セルには1つの値しか入れてはいけない。 Figure 2.10: 規則3の例：雑然データ この例を整然データに直すなら，図2.11のように新たに「売上高（修正）」の変数を作り，修正された売上高はそこの列に配置することになる。売上高の修正のない観測は，「売上高（修正）」を「NA」として欠損値で扱っておけば問題ない12。 Figure 2.11: 規則3の例：整然データ 以上のように整然データとして構築されたデータは，Rなどの統計ソフトで容易に扱うことができる。 ある1列を指定すればその列の変数が取り出せるし，ある1行を指定すればその行の観測が取り出せる。 また，セルは1つの値しか入ってないので，そのセルを指定するだけで欲しい値を取り出すことができる。 このように，整然データに従ってデータを構築すれば，データ分析を効率的に行うことができるようになる。 財務情報はバフェット・コードといったサイトでも入手可能である。企業の財務情報を収集するのは手間がかかるが，このサイトを利用することで，簡便に企業の財務情報にアクセスできる。↩︎ 金融庁が提供する有価証券報告書等の企業が開示する書類を閲覧できるウェブサイト。過去5年分 の開示書類が収録されている。EDINETは，Electronic Disclosure for Investors’ NETworkの略称。↩︎ EDINETを利用してデータを自動取得することもできる。ただし，そのためにはウェブ・クローリングに関する知識が必要となる。↩︎ “12 Tidy data,” R for Data Science,https://r4ds.had.co.nz/tidy-data.html, 2021年3月10日閲覧。なお，Wickham (2014) では，下記の規則3はなく，代わりに「それぞれの種類の観測単位は，ある表を構成する」がある。これは，会計データの分析に必要な財務情報は，バラバラの表にではなく，1つの表に集めなければならない，と解釈できる。↩︎ 「企業年」はある1企業のある1年度の観測値を示す単位である。 「川崎重工業の2018年度」という観測値に対して「1企業年」という数え方をする。 ここでの例の場合，3企業の3年度ずつの会計データが取得されており，3企業 \\(\\times\\) 3年度 \\(=\\) 9つの観測値が存在する。 そのため，9企業年となる。↩︎ 「行」は表の横の並び，「列」は表の縦の並びを示す。行列の覚え方についてはこのウェブページが詳しい。「行列で縦か横か迷ったら」Colorless Green Ideas, https://id.fnshr.info/2015/10/17/matrix/, 2021年3月10日閲覧↩︎ 以下の解説は，このウェブページを参考に作成されている。「整然データとは何か」Colorless Green Ideas, http://id.fnshr.info/2017/01/09/tidy-data-intro/, 2021年3月10日閲覧。↩︎ 値が欠損しているときに使われる記号。Rでは，「NA」とセルに記載されていれば，当該値は「欠損値」として扱われる。ちなみに，NAは，not applicable，あるいはnot availableの略称。↩︎ "],["03-Rの準備.html", "Chapter 3 R・Rstudioの準備と基本操作 3.1 この章について 3.2 インストール 3.3 RStudioの基本操作とRの基礎知識", " Chapter 3 R・Rstudioの準備と基本操作 &lt;学習目標&gt; ・RおよびRStudioをインストールする。 ・RおよびRStudioの基本操作・基礎知識について学習する。 ・会計データの読込・操作・書出ができる。 【応用例】 なし 【関連する会計研究】 なし 3.1 この章について この章では，会計データの分析をするうえで強力なツールとなるRおよびRStudioの基本操作を学習する。 財務諸表分析，費用直線の推定，利益調整の検証などの会計データを使った分析をしたいとき，データを読み込み，整理し，解析し，結果を出力するという一連の操作を行う必要がある。 簡単な分析や容量の軽いデータなら，これらの操作をExcel上で行うのも良いだろう。 しかし，Excelは高度な統計解析を行うには適していない。 そのため，Excelで統計解析を行うと，(1) 高度な統計解析ができない(もしくは極端に手間がかかる)，(2) データ量が多いためPCの動作が重たくなる，(3) 統計解析の過程を残しづらい，といった問題に突き当たる。 本書では，統計解析をする際に使用されるソフトウェアのなかで，おそらく世界中で利用者数が最も多いであろうRをつかって，会計データを分析する。 Rとは，統計解析のためのフリーソフトウェアである。 さらに，Rはオープンソースのソフトウェアであるため，GNU使用許諾のもとで自由に共有・改変することが認められている。 そのため，世界中の優秀なエンジニアによってRの修正や機能追加が日夜進められている。 最新の統計分析から，会計学研究で使用されているような専門的な分析手法まで，現在使われているほとんどの統計解析方法がRでは無料で利用できる。 Rは利用者も多いため，わからないことがあるときや，エラーが出て分析がうまくいかないときには，インターネット上で検索を行うことで，多くの問題を簡単に解決することができるだろう。 さて，会計データを使った分析をR上で行うには，自分のPCにRをインストールし，そこに会計データを読み込み，Rを操作し，分析結果を出力する必要がある。 本章では，RのインストールからRの基本操作までを解説する。 まず，RおよびRの統合開発環境であるRStudioのインストールを行う。次に，RおよびRStudioの基本操作と基礎知識を確認する。 3.2 インストール 3.2.1 Rのインストール Rは開発元のCRANから簡単にダウンロードすることができる(https://cran.r-project.org/)。使用するPCがWindowsの場合は上記サイトへアクセス後，画面表示される「Download R for Windows」を選択する。 Figure 3.1: Rのインストール1 その後，「install R for the first time」を選択し， Figure 3.2: Rのインストール2 「Download R x.x.x(最新バージョンの番号) for Windows」をクリックするとダウンロードを開始される13。 Figure 3.3: Rのインストール3 Macを使用する場合は，CRANへアクセス後に「Download R for (Mac) OS X」をクリックする。 クリックすると表示されるページの下部に「R x.x.x.(最新バージョンの番号).pkg」とあるので，最新バージョンを入手する場合はこちらをクリックしダウンロードを開始する。 古いバージョンを取得したい場合，同ページの「el-capitan/base」や「old」をクリックしてから，ダウンロードしたいバージョンを選択する14。 Rのダウンロードが完了したら，PC上でRを動かすことが可能になる。 ダウンロード後に表示されるRのアイコンからRを起動してみよう。 WindowsもしくはMacどちらで起動しても，次のように表示される。 Figure 3.4: Rの起動 ここでは，Rのバージョンと注意事項が表示されている。 画面の一番下には「&gt;」と表示されているはずである。 この「&gt;」はRが命令を待っている状態を意味する。 試しに，Rに計算をさせてみよう。 「&gt;」の右に「1 + 2」と入力してエンターキーを押す。 1 + 2 ## [1] 3 画面には「[1] 3」とRによる計算結果が表示されたはずである。 [1]は計算結果が1つであることを意味している。 Rでは，このような足し算(+)だけでなく，引き算(-)，掛け算(*)，割り算(/)，累乗(^)といった演算が使える。 このような演算の他にも，様々な関数が使用できる。 例えば，2のルートを計算したい場合はsqrt()関数を使う。 sqrt(2) ## [1] 1.414214 このように，sqrt()のカッコ内に数値を入力すればRに計算させることができる。 sqrt()関数の他にも，データ分析によく使う簡単な関数として自然対数(log)，四捨五入(round)などの関数がある。 関数は膨大な数がR上に用意されている。 本書では，必要に応じて適宜紹介する。 Rでは，次の2ステップを繰り返すことでデータ分析を進めていく。 コードを入力して，Rに命令する。 Rが計算を行い，命令された結果が返ってくる このように，Rでは1つの命令を入力するごとに結果を確認できることから，Rはインタラクティブな言語だといわれている。 3.2.2 RStudioのインストール Rだけでもデータ分析はできる。 とはいえ，本格的にデータ分析を行うのであれば，便利な機能が豊富に用意されている統合開発環境(Integrated Development Environment; IDE)を介してRを動かす方が便利だろう。 統合開発環境のなかでも最も代表的なものがRStudioである。 本書でもRStudioを用いて解説を行う。 Rstudioは，https://rstudio.com/products/rstudio/からデスクトップ版をダウンロードして使用する。 無料版と有料版があるが，無料版で十分である。本書では，RStudio 1.1.643 を使用している。 ダウンロード手順は，サイトにアクセスして， Figure 3.5: Rstudioのインストール1 ページ中部にあるRstudio Desktopの「Download RStudio Desktop」をクリックし， Figure 3.6: Rstudioのインストール2 RStudio DesktopのFREEをダウンロードをクリックし， Figure 3.7: Rstudioのインストール3 WindowsかMacの最新バージョンのRStudioをクリックしてダウンロードする。15。ダウンロードしたファイルをインストールすることで，RStudioを使用することができるようになる16。 Figure 3.8: Rstudioのインストール4 3.3 RStudioの基本操作とRの基礎知識 3.3.1 RStudioの基本操作 RStudioを立ち上げると，このような画面が表示される。 Figure 3.9: Rstudionの起動 この画面が表示された場合はNew Directoryを選択後，New Projectを選択する。 このプロジェクトとは，RStudioで行う分析に関連するファイルをまとめて管理してくれる機能である。 ファイルの管理や，gitによるバージョン管理などを行うことができる。 New Projectを選択後，このプロジェクトをどこのディレクトリ(場所)に作成するか聞いてくるので，プロジェクトを保存したいディレクトリとプロジェクトの名前を入力する。 RStudioで分析を行うときは，分析ごとにこのプロジェクトを立ち上げる。 プロジェクトの設定が終わればこのような画面が表示されるはずである。 初期画面ではRStudioは3つに区切られている。 しかし，分析を行うときには，画面を4つに区切ることが多い。 そこで，左側画面の右上にある画面が2つ重なったマークをクリックして，ウィンドウを4つに区切ってみよう。 なお，この区切られた画面1つ1つをペインとよぶ。 Figure 3.10: Rstudioの画面 このように4つのペインが表示されたら，準備は完了である。 以下では，会計データを分析するのに最低限必要な各ペインの役割を確認していく。 Figure 3.11: Rstudionのペイン まず，左下のペインはコンソール(console)とよばれる。 ここはRとのやりとりをする場所である。 四則演算や平方根の計算など，先ほど試しに実行したRとのやりとりはここで行うことができる。 次に，左上のペインはソース(source)とよばれ，Rへ命令するコードの読み込み・書き込み・保存ができるペインになる。 データ分析を行うとき，「元データからどのような操作を行って分析結果が得られたのか」を記録しておく必要がある。 もし，この記録がなければ，どのような操作で分析結果が得られたのかわかりづらく，複雑な分析では同じ分析結果を再び得ることも難しい。 これは，分析結果の信頼性を得られなくなることを意味する。 そこで，R上でどのような操作を行ったかを記録しておく必要がある。 コンソールペイン上のRとのやりとりを保存してもよいが，次の2つの問題がある。 1つ目は，コンソールペインでのやりとりは命令の入力内容と結果の出力が交互に表示される点である。 そのため，「R上でどのような操作を行ったのか」という命令の入力だけを見たい場合，結果の出力も表示されるコンソールペインのやりとりでは，記録が長くなってしまう。 2つ目は，Rでは誤ったコードを入力してしまった場合でも，エラーという結果を返してくれる点である。 まだRの操作になれていないとき，あるいは慣れない関数を使ったときなどは，エラーと格闘しながら誤ったコードを修正することになる。 コンソールペインでのやりとりは，このようなエラーも記録されてしまうため，記録が誤ったコードとエラーだらけになってしまう。 したがって，コンソールペインとは別に，コードを記録するする場所が必要になる。 この記録を残す場所がソースペインである。 ソースペインでの記録は，コードの清書だと思ってもらえればよい。 一般に，プログラミングにかかる時間の多くはコードを打ち込む時間ではなく，入力したコードを確認・修正する時間だといわれている。 これは会計のデータを分析するときでも同様である。 複雑な分析をするとき，R上のコードは数十行，場合によっては数百行に及ぶ。 このような長文のコードを取り扱うとき，コードの視認性が悪いと作業効率が大幅に低下してしまうだろう。 そのため，R上で行った操作を見やすい形式に清書して，ソースペインに記録することは，作業の効率化の観点からも重要な作業である。 それでは，先ほど実行した簡単なコードをソースペインに清書してみよう。 下記コードを左上のソースペインに入力する。 なお，「#」はコメントアウトの記号であり，「#」と同じ行の右側のコードはRにすべて無視される。 Rへの命令ではなく，自分を含めユーザーへコメントを残したい場合に使用する。 コードがかけたら，ソースペインの実行したい範囲をドラッグで指定し，Ctrl+Enter（Macの場合はcommand + Enter）を押すと，左下のコンソールペインで実行される17。 1 + 2 ## [1] 3 sqrt(2) ## [1] 1.414214 このようにソースペインに入力したコードからでも，コンソールペインでのやりとりを再現できる。 それでは，このスクリプトファイルを実際に保存してみよう。 ファイルを保存するには，ソースペインのフロッピーディスク(保存)アイコンをクリックすると保存できる。 なお，新規のスクリプトファイルを開く場合には，画面左上の白紙アイコンを，既存のスクリプトファイルを開く場合には，フォルダが開いているアイコンをクリックする。 Figure 3.12: ファイルの保存 3.3.2 Rの基礎知識 簡単なRとのやりとりがRStudio上で実行できるようになったところで，会計データ分析をするために最低限必要なRおよびRStudioの基礎知識を学習しよう18。 ベクトル 代入 データ型 パッケージ まず，読み取った会計データは，ベクトルとして操作することが多い。 ベクトルとは，(1, 2, 3)のような数字列のことである。 R上でデータをベクトルだと認識させるためには，括弧の前にcをつけて，c(1, 2, 3)と表記する。 このベクトルをつかって，下記のように演算や関数を適用してみよう。 # ベクトル c(1, 2, 3) + c(2, 3, 4) ## [1] 3 5 7 c(1, 2, 3) * c(2, 3, 4) ## [1] 2 6 12 sqrt(c(1, 2, 3)) ## [1] 1.000000 1.414214 1.732051 ベクトルを演算するとき，演算のたびにc(1, 2, 3)と書くのは大変である。 もし，c(1, 2, 3)というのをどこかに格納しておき，その格納した場所で演算するよう指示できれば，入力するコードが短くてすむ。 このベクトルなどををどこかへ格納する操作を「代入」とよぶ。 そこで，c(1, 2, 3)とc(2, 3, 4)をvec1とvec2という新たに作成した変数に代入してみよう。 # 代入 vec_1 &lt;- c(1, 2, 3) vec_2 &lt;- c(2, 3, 4) これで，c(1, 2, 3)をvec1に，c(2, 3, 4)をvec2に代入できた。 先ほどと同じ演算および関数をvec1とvec2に適用してみると，同じ結果が得られるだろう。 vec_1 + vec_2 ## [1] 3 5 7 vec_1 * vec_2 ## [1] 2 6 12 sqrt(vec_1) ## [1] 1.000000 1.414214 1.732051 ベクトルには数値だけではなく，文字も入力することができる。 たとえば，下記のように記述する。 # 型 char_vec &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) char_vec ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; しかし，当然ながら文字と数値は足し算などをすることはできない。試しに下記のコードを実行してみると，このようなエラーが表示されるだろう。 vec_1 + char_vec エラーからわかるように，Rでは入力されたベクトルや値が数字なのか文字なのか，データの形式を認識している。 これをデータ型という。 データ型には実数(numeric;double;integer)，整数(integer)，文字(character)，論理値(logical)，日付(Date)などがある。 変数の型を調べるにはclass()関数を使う。 分析を行うときは，データ型に注意しよう19。 class(vec_1) ## [1] &quot;numeric&quot; class(char_vec) ## [1] &quot;character&quot; Rでは，関数とデータを機能別にまとめたパッケージ（もしくはライブラリ）とよばれるコード・ライブラリがある。 このパッケージは世界中のRユーザーによって作成されており，数千種類もの数が存在する。 たとえば，高速な分析を可能にするtidyverse，きれいなグラフを出力するggplot2，心理統計でよく使用される手法をまとめたpsychなどがある。 Rでは既存の関数でやりたいことが実行するのが難しいとき，このパッケージをインストールして，パッケージに含まれている関数を使う。 パッケージをインストールするには，install.packages()関数を使う20。 install.packages()関数を利用する場合には，パッケージの名前をダブルクオーテーション（\"\"）でくくる必要があることに注意しよう。 また，「Do you want to install from sources the package which needs compilation? (Yes/no/cancel)」と表示された場合は「Yes」と入力すること。 本書では，tidyverseというパッケージの関数を使用してデータ処理をする。 試しにこのtidyverseをインストールしてみよう。なお，このテキストでは tidyverse 1.2.1を使用する。 # パッケージのインストール install.packages(&quot;tidyverse&quot;) これでパッケージのインストールは完了である。 インストールしたパッケージを使うには，R上でパッケージをロードする必要がある。 パッケージのロードには，library()関数もしくはrequire()関数を使う21。 # パッケージの読み込み library(tidyverse) 古いバージョンのRを取得したい場合は，最後のページの下部にある「Previous releases」をクリックすれば，各バージョンのダウンロードページへのリンクが表示される。このテキストでは，R 3.5.1.を使用している。↩︎ Macの場合はOSによっては対応していないバージョンもあるため，ダウンロード時にはページの注意事項を確認してからダウンロードすること。↩︎ サイトの画像は2021年3月16日時点のもの。↩︎ RStudioをダウンロードしなくともRStudio cloudというRStudioをクラウド上で操作できるサービスもあるhttps://rstudio.cloud/)。このサービスはアカウントを作成するか，もしくはGoogleアカウント・GitHubアカウントをもっていれば利用できる。開発中のアルファ版ではあるが，異なるPC環境でもサーバー上で同じ動作をするので授業等にはこちらの方が便利かもしれない。なお，RStudio cloudではローカルフォルダではなく，サーバー上フォルダを利用するのでデータをアップロードする必要があることに注意してほしい。↩︎ 本書では，Rを実行した結果について，コンソールペインに写し出される結果を掲載している。↩︎ 紙幅の関係からここでは以下の基礎知識についてのみ説明する。ここでの説明で足りないと感じる読者は， 舟尾 (2009) 『The R tips』(オーム社)や Lander (2017) 『みんなのR (第2版)』（マイナビ出版）などR自体のテキストを参照してほしい。↩︎ 特に，数値データであるにも関わらずR上では文字型(character)として認識されていることもある。これはデータの中に数字ではないデータが入っている場合にしばしば発生するので注意すること。↩︎ パッケージのダウンロードにはこの他に，RStudioのToolsタブからダウンロードする方法，右下ペインのpackageタブを開き，そこからダウンロードする方法などもある。↩︎ なお，tidyverseを読み込むと，上記のようにconflictsと表示されることがある。これはRにデフォルトで入っている関数とtidyverseに入っている関数で名前が重複する関数があることを意味している。分析するときには注意しよう。今回はデフォルトで入っているstatsパッケージと重複しているので，デフォルトの関数を使いたいときにはstats::lagのようにパッケージ名にコロンを2つ(::)をつけたあと，関数名を記入すればよい。↩︎ "],["04-会計情報の前処理.html", "Chapter 4 会計情報を前処理する 4.1 この章について 4.2 データの読込・操作 4.3 データの結合 4.4 財務指標の作成", " Chapter 4 会計情報を前処理する &lt;学習目標&gt; ・読み込んだ会計データと他のデータとの結合・整理が実行できる ・財務数値を作成し，記述統計量をグループ間で比較できる 【応用例】 業界間での収益性指標の比較 上場年数で分けたグループ間での費用構造の比較 【関連する会計研究】 Srivastava, A. (2014) `‘Why have measures of earnings quality changed over time?’’ Journal of Accounting and Economics, Vol. 57, No, 2–3, pp. 196-217. 4.1 この章について この章では，データセットを利用して会計データを分析する方法を学習する。 第3章では，RおよびRstudioの操作環境を整え，これらの基本操作について学習した。 しかし，実際に会計情報を分析するには，会計データをR上に読み込む必要がある。 さらに，会計データだけではなく他のデータも合わせて利用する場面も多い。 たとえば，産業データ，株価データ，マクロデータといったデータセットである。 このような他のデータと会計データを組み合わせることで，会計データに産業データを結合して産業間でROEを比較する，会計データに株価データを結合して時価簿価比率を計算するなどの分析ができる。 こうした複数のデータセットを利用した分析をするには， 会計データと結合したい他のデータセットの両方を読み込んだうえで2つのデータセットを結合・整理する，(2) 結合・整理したデータセットで財務数値を計算する，という作業が必要になる。 この章では，(1) データの読込・結合・整理，(2) 財務指標の作成と要約を学習する。 この章で学習する分析は非常にシンプルだが，そのシンプルさゆえに強力な証拠にもなりうる。 たとえば，この章で学習する分析を利用した興味深い研究として， Srivastava (2014) が挙げられる。 米国企業では費用収益対応が一貫して低下しており，会計情報が役立たたなくなっているのではないかという議論がある。 Srivastava (2014) は，販売費および一般管理費（以下，販管費）の支出割合が高い新規企業が参入することで，米国企業における費用収益対応が低下したのではないかと主張した。 会計処理上，売上原価は売上高と個別対応であるのに対して，販管費は期間対応である。 そのため，新しい企業ほど総費用に占める販管費の割合が高ければ，そのような企業が新規参入することでサンプル全体の費用収益対応の程度は低下するだろう。 この論文で行われた分析は，企業を上場時期ごとにグループ分けし，グループ間で総費用に占める販管費の割合を比較するというシンプルな分析だった。 分析結果は，上場年数の新しいグループは販管費の割合が高く，逆に上場年度の古いグループは売上原価の割合が高いという予想通りのものだった。 Srivastava (2014) の分析結果は，そのシンプルさ故に強力な証拠になっている。 Srivastava (2014) と同様の分析を行うには，会計データに上場年数のデータセットを結合し，上場年数のグループ間で総費用に占める各費用の割合を計算するという操作が必要になる。 いずれも，この章で学習する操作ができれば実行できる。 4.2 データの読込・操作 4.2.1 データの読込 まずは，会計データの読み込み・操作・書き出しまでを実際にやってみよう。 本章では「findata.csv」というデータを使用する。 データを読み込むために，読み込みたいcsvファイル (findata.csv) をプロジェクトのあるディレクトリ（Rプロジェクトで作成されたフォルダ内）に保存する。 プロジェクト内のファイルはRStudioの右下のファイルズ (files) ペインに表示される。 csvファイルを読み込むには，tidyverseパッケージのread_csv()関数22を使用する。 Macユーザーは文字エンコードの関係からread_csv()関数の引数にlocale=locale(encoding=\"CP932\")をつけることに注意してほしい。 なお，Rでは，「,（コンマ）」や「+」など必ず次に何らかのコードが来る文字で改行した場合は，「複数行で書いた場合も1行の命令」として実行される。 library(tidyverse) # データの読み込み df_0 &lt;- read_csv(&quot;findata.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## ## ─ Column specification ──────────────────────────── ## cols( ## 銘柄コード = col_double(), ## 会社名 = col_character(), ## 売上高 = col_double(), ## 売上原価 = col_double(), ## 販管費 = col_double(), ## 当期純利益 = col_double(), ## 総資産 = col_double(), ## 負債 = col_double(), ## 有利子負債 = col_double(), ## 純資産 = col_double(), ## 現金及び預金 = col_double(), ## 売上債権 = col_double(), ## 棚卸資産 = col_double(), ## 仕入債務 = col_double(), ## 法人税等 = col_double() ## ) 読み込みに成功したら，データセットに含まれる変数名が表示される。 親切なことに，read_csv()関数は読み込んだデータの各列が，どのデータ型として読み込まれたのかも合わせて表示してくれる。 表示によると，このデータセットの列（col）は，実数型（double）もしくは文字型（character）のいずれかで読み込まれている。 4.2.2 データの操作 RStudioでは，右上の環境 (environment) ペインに読み込んだデータが表示される。 表示をみてみると，15の列（財務数値などの変数）をもつ18行（企業）のデータセットであることがわかる。 実際に読み込んだデータを確認してみよう。 環境ペインに表示されているdf_0の右にある表のアイコンをクリックすると，Excelのような形式で読み込んだデータが表示される。 また，コンソールペインにdf_0と打ち込むとdf_0の一部分が表示される。 # データの表示 df_0 ## # A tibble: 18 x 15 ## 銘柄コード 会社名 売上高 売上原価 販管費 当期純利益 総資産 負債 有利子負債 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品… 2.68e5 211068 52563 3869 1.83e5 91422 32019 ## 2 2730 エディオン… 6.86e5 488119 182786 8944 3.70e5 200541 65930 ## 3 3048 ビックカメラ… 8.44e5 607947 209025 17122 3.66e5 209839 95576 ## 4 3088 マツモトキヨ… 5.59e5 389673 135639 22755 3.15e5 110290 0 ## 5 3098 ココカラファ… 3.91e5 286311 90939 9067 1.58e5 70368 300 ## 6 3141 ウエルシアホ… 6.95e5 485320 181121 17166 2.92e5 161756 44225 ## 7 3148 クリエイトS… 2.68e5 194479 59819 9540 1.21e5 52035 0 ## 8 3349 コスモス薬品… 5.58e5 447681 87568 17633 2.51e5 141720 9816 ## 9 3391 ツルハホール… 6.73e5 480402 152599 24798 3.40e5 135697 15335 ## 10 7419 ノジマ 5.02e5 383819 101026 13634 2.60e5 191272 70857 ## 11 7513 コジマ 2.46e5 179616 62526 3418 1.01e5 59165 31667 ## 12 7649 スギホールデ… 4.57e5 325481 106804 16411 2.54e5 91943 0 ## 13 8173 上新電機… 3.92e5 300187 81858 5579 1.89e5 108127 39216 ## 14 8202 ラオックス… 6.43e4 37999 26153 104 6.35e4 19000 9221 ## 15 8282 ケーズホール… 6.79e5 487499 160868 22706 4.04e5 161298 58377 ## 16 9627 アインホール… 2.68e5 220392 28370 10567 1.83e5 86702 16803 ## 17 9831 ヤマダ電機… 1.57e6 1135758 399351 29779 1.18e6 586827 310948 ## 18 9989 サンドラッグ… 5.64e5 423256 104878 24829 2.47e5 91790 0 ## # … with 6 more variables: 純資産 &lt;dbl&gt;, 現金及び預金 &lt;dbl&gt;, 売上債権 &lt;dbl&gt;, ## # 棚卸資産 &lt;dbl&gt;, 仕入債務 &lt;dbl&gt;, 法人税等 &lt;dbl&gt; このままでは15列もあるため，少し見辛い。 そこで，df_0の1列目から4列目までと，6列目だけを表示させてみよう。 Rでは「１から４」のことを1:4と記入する。 そのため，「１から４と６」を指定したいときは，1:4,6と記入する。 df_0[, c(1:4, 6)] ## # A tibble: 18 x 5 ## 銘柄コード 会社名 売上高 売上原価 当期純利益 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 3869 ## 2 2730 エディオン 686284 488119 8944 ## 3 3048 ビックカメラ 844029 607947 17122 ## 4 3088 マツモトキヨシホールディングス 558879 389673 22755 ## 5 3098 ココカラファイン 390963 286311 9067 ## 6 3141 ウエルシアホールディングス 695268 485320 17166 ## 7 3148 クリエイトSDホールディングス 268161 194479 9540 ## 8 3349 コスモス薬品 557999 447681 17633 ## 9 3391 ツルハホールディングス 673238 480402 24798 ## 10 7419 ノジマ 501890 383819 13634 ## 11 7513 コジマ 246391 179616 3418 ## 12 7649 スギホールディングス 457047 325481 16411 ## 13 8173 上新電機 391726 300187 5579 ## 14 8202 ラオックス 64291 37999 104 ## 15 8282 ケーズホールディングス 679132 487499 22706 ## 16 9627 アインホールディングス 268385 220392 10567 ## 17 9831 ヤマダ電機 1573873 1135758 29779 ## 18 9989 サンドラッグ 564215 423256 24829 このように，データセットの一部のみを指定する場合は，df_0[指定する行ベクトル,指定する列ベクトル]と記入する。 なお，上記と同じ操作を下記の4つのどの記入方法でも実行することができる。 # 下記4つはすべて同じ操作 df_0[, c(1:4, 6)] df_0[, c(&quot;銘柄コード&quot;, &quot;会社名&quot;, &quot;売上高&quot;, &quot;売上原価&quot;, &quot;当期純利益&quot;)] select(df_0, 銘柄コード, 会社名, 売上高, 売上原価, 当期純利益) df_0 %&gt;% select(銘柄コード, 会社名, 売上高, 売上原価, 当期純利益) 上記4つのどのコードでも同じ操作ができるのだが，どのコードで記述するのが良いだろうか。 プログラミングで最も大事なことは，「読みやすいコード」を書くことである。 プログラミングで何かするとき，ほぼすべての工程でコードを読むという作業が発生する。 プログラムの作業時間のほとんどは「コードを書く」ことではなく，「コードを読む」ことにかけられる。 したがって，作業効率の観点から，読みやすく理解しやすいコードを書くことが大事になる。 コードの読みやすさ，理解しやすさの度合いは「可読性」と呼ばれる。 それでは，上記4つのうち可読性の高いコードはどれだろうか。 結論からいえば，4つ目のコードが最も可読性が高い。 まず，1つ目のコードdf_0[, c(1:4, 6)]は文字数が少なくコードを打ち込むのは楽そうである。 しかし，あとになってこのコードを見直したとき「あれ？6行目って何の数値だったっけ？」となってしまうかもしれない。 2つ目のコードの記述はシンプルではあるものの，コードからどのような操作をしているのか分かりづらい。 一方，3，4つ目は「select」とあるので，「変数を選択しているんだな」とRを知らない人でさえ何となく理解できるコードになっている。 しかも，select()関数を使う際には「\"\"（ダブルクオーテーション）」も必要なく，記述が楽である。 4つ目のコードには少し説明が必要だろう。 4つ目のコードで使用されている「%&gt;%」は，パイプ演算子と呼ばれる。 パイプ演算子を正確に説明すると「直前に記載されてある変数を直後に記載されてある関数の第1引数として渡す」という操作を行う。 なんだか難しそうだが，使い方はシンプルだ。 基本的に「dfというデータに対して，Aという作業をする」というコードを書きたければdf %&gt;% Aの作業コードと記入すればよい。 パイプ演算子を使うことで，df_0をselect()関数の外に出すことができるため，4つ目のコードが最も読みやすい。 パイプ演算子のメリットは，複数の作業をするときの可読性が高いことだ。 例えば，「dfというデータに対して，Aという作業して，その作業をしたものに対してBという作業をして，…」ということをしたいときは，df %&gt;% Aの作業コード %&gt;% Bの作業コード %&gt;% ...と数珠つなぎで記入すればよい。 パイプ演算子の利用は，最初難しく感じるかもしれないが，慣れてくるとパイプ演算子を使ったほうが断然読みやすい。 パイプ演算子の練習として，「dfというデータセットに対して，いくつかの列を選択して，それから列名を変更する」という作業をしてみよう。 列名を変更するには，rename()関数を使う。 Rでは，列名が日本語だと分析上取り扱いにくいことが多い。 そのため，rename()関数を使って変数名を英語表記に変更する。 ここでは，「銘柄コード，会社名，売上高，売上原価，販管費，総資産」の6つの列を選択し，これらの変数名をそれぞれid，name，sales，cogs，sga，asset」に変更してみる。 # データセットに対して，列を選択して，列名を変更する df_0 %&gt;% select( 銘柄コード, 会社名, 売上高, 売上原価, 販管費, 総資産 ) %&gt;% rename( id = 銘柄コード, name = 会社名, sales = 売上高, cogs = 売上原価, sga = 販管費, asset = 総資産 ) ## # A tibble: 18 x 6 ## id name sales cogs sga asset ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 ## 2 2730 エディオン 686284 488119 182786 369547 ## 3 3048 ビックカメラ 844029 607947 209025 365605 ## 4 3088 マツモトキヨシホールディングス 558879 389673 135639 315161 ## 5 3098 ココカラファイン 390963 286311 90939 158179 ## 6 3141 ウエルシアホールディングス 695268 485320 181121 292238 ## 7 3148 クリエイトSDホールディングス 268161 194479 59819 121412 ## 8 3349 コスモス薬品 557999 447681 87568 250609 ## 9 3391 ツルハホールディングス 673238 480402 152599 339686 ## 10 7419 ノジマ 501890 383819 101026 260291 ## 11 7513 コジマ 246391 179616 62526 101479 ## 12 7649 スギホールディングス 457047 325481 106804 253989 ## 13 8173 上新電機 391726 300187 81858 189019 ## 14 8202 ラオックス 64291 37999 26153 63527 ## 15 8282 ケーズホールディングス 679132 487499 160868 403658 ## 16 9627 アインホールディングス 268385 220392 28370 183435 ## 17 9831 ヤマダ電機 1573873 1135758 399351 1175568 ## 18 9989 サンドラッグ 564215 423256 104878 246619 このようにパイプ演算子を使うことで，1連の作業をひとまとまりのコードで書くことができる。 なお，このままではせっかく英語表記に直したデータセットがどこにも保存されていないので，新しくdf_1というデータセットに保存し直しておく。 保存したあとは，データセットの上から6行目までを表示してくれるhead()関数で確認しておこう。 # データセットに対して，列を選択して，列名を変更する df_1 &lt;- df_0 %&gt;% select( 銘柄コード, 会社名, 売上高, 売上原価, 販管費, 総資産 ) %&gt;% rename( id = 銘柄コード, name = 会社名, sales = 売上高, cogs = 売上原価, sga = 販管費, asset = 総資産 ) # 確認 head(df_1) ## # A tibble: 6 x 6 ## id name sales cogs sga asset ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 ## 2 2730 エディオン 686284 488119 182786 369547 ## 3 3048 ビックカメラ 844029 607947 209025 365605 ## 4 3088 マツモトキヨシホールディングス 558879 389673 135639 315161 ## 5 3098 ココカラファイン 390963 286311 90939 158179 ## 6 3141 ウエルシアホールディングス 695268 485320 181121 292238 なお，select()関数では，列を選択する際に，変数名を変更することもできる。 その際には以下のようにコードを書けばよい。 df_0 %&gt;% select( id = 銘柄コード, name = 会社名, sales = 売上高, cogs = 売上原価, sga = 販管費, asset = 総資産 ) ## # A tibble: 18 x 6 ## id name sales cogs sga asset ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 ## 2 2730 エディオン 686284 488119 182786 369547 ## 3 3048 ビックカメラ 844029 607947 209025 365605 ## 4 3088 マツモトキヨシホールディングス 558879 389673 135639 315161 ## 5 3098 ココカラファイン 390963 286311 90939 158179 ## 6 3141 ウエルシアホールディングス 695268 485320 181121 292238 ## 7 3148 クリエイトSDホールディングス 268161 194479 59819 121412 ## 8 3349 コスモス薬品 557999 447681 87568 250609 ## 9 3391 ツルハホールディングス 673238 480402 152599 339686 ## 10 7419 ノジマ 501890 383819 101026 260291 ## 11 7513 コジマ 246391 179616 62526 101479 ## 12 7649 スギホールディングス 457047 325481 106804 253989 ## 13 8173 上新電機 391726 300187 81858 189019 ## 14 8202 ラオックス 64291 37999 26153 63527 ## 15 8282 ケーズホールディングス 679132 487499 160868 403658 ## 16 9627 アインホールディングス 268385 220392 28370 183435 ## 17 9831 ヤマダ電機 1573873 1135758 399351 1175568 ## 18 9989 サンドラッグ 564215 423256 104878 246619 4.3 データの結合 次に，業種データを作成して読み込む。 なお，東証業種分類など公式な分類であれば，手入力しなくても日経NEEDSなどのデータベースからダウンロードすることができる。 今回は，業界リサーチの家電量販店とドラッグストアのサイトをもとに，銘柄コード，会社名，業界という3つの列からなるデータセットを手入力で作成し，「inddata.csv」というファイルを作成した。 このデータセットを読み込んだうえで，必要な列を選択して，英語表記に直して新しいデータフレームdf_ind_1に代入しておこう。 # 業界データの読み込み df_ind_0 &lt;- read_csv(&quot;inddata.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## ## ─ Column specification ──────────────────────────── ## cols( ## 銘柄コード = col_double(), ## 会社名 = col_character(), ## 業界 = col_character() ## ) # 変数名の変更 df_ind_1 &lt;- df_ind_0 %&gt;% select( id = 銘柄コード, ind = 業界 ) この業種データ（df_ind_1）と会計データ（df_1）に結合してみよう。 データセットの結合には，結合キーが必要になる。結合キーとは，２つのデータセット間でどの行どの行を紐付けるかの目印となる変数のことだ。 例えば，会計データでのカワチ薬品の行には，業種データでのカワチ薬品の行を結合したい。 このように両データセットでデータ間に対応関係がある場合，どのデータ同士を紐付けるか目印となる変数が必要になる。 今回のケースでは，どちらのデータセットにもidという同じ変数が含まれているので，これを結合キーとして利用する。 それでは，2つのデータセットを結合しよう23。 今回は両データセットに共通する行だけを残したいので，inner_join()関数をつかって結合する。 結合キーには銘柄コード (id) を使用する。 なお，inner_join()関数以外にも，左側に記入するデータセットの行をすべて残すleft_join()関数，両方のデータセットの行をすべて残すfull_join()関数がある。 結合できたら，head()関数で結果を確認してみよう。 また，このデータセットに，どういう業界が何社含まれているか確認するには，table()関数を使用する。 table()関数は度数を計算するための関数で，データセットに各業界のデータがどれだけ含まれているかを出力してくれる。 # データの結合 df_2 &lt;- inner_join(df_1, df_ind_1, by = &quot;id&quot; ) # 上から6行目まで確認 head(df_2) ## # A tibble: 6 x 7 ## id name sales cogs sga asset ind ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 ドラッグストア… ## 2 2730 エディオン 686284 488119 182786 369547 家電 ## 3 3048 ビックカメラ 844029 607947 209025 365605 家電 ## 4 3088 マツモトキヨシホールディングス 558879 389673 135639 315161 ドラッグストア… ## 5 3098 ココカラファイン 390963 286311 90939 158179 ドラッグストア… ## 6 3141 ウエルシアホールディングス 695268 485320 181121 292238 ドラッグストア… # 業界ごとの度数の確認 df_2 %&gt;% select(ind) %&gt;% table() ## . ## ドラッグストア \\u5bb6\\u96fb ## 10 8 table()関数の結果より，結合されたデータセットの内訳が確認できる。 以下では，ドラッグストア業界に属する企業10社と家電量販店業界に属する企業8社で財務数値を比較していく。 なお，Rは日本語の取り扱いがそれほど得意ではないので，業界名を英語に修正しておく。業界の英語名を示すind_engという新しい列をデータセットに追加する。 データセットに列を追加するにはmutate()関数を使う。 今回は，indの列に記入されている日本語名を英語名に置き換えたいので，recode()関数も使って以下のように記入する。 # 業界名を英語に変更 df_2 &lt;- df_2 %&gt;% mutate( ind_eng = recode( ind, &quot;ドラッグストア&quot; = &quot;DrugStore&quot;, &quot;家電&quot; = &quot;ElectronicsRetail&quot; )) head(df_2) ## # A tibble: 6 x 8 ## id name sales cogs sga asset ind ind_eng ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 ドラッグストア… DrugStore ## 2 2730 エディオン 686284 488119 182786 369547 家電 Electronics… ## 3 3048 ビックカメラ 844029 607947 209025 365605 家電 Electronics… ## 4 3088 マツモトキヨシホールディングス… 558879 389673 135639 315161 ドラッグストア… DrugStore ## 5 3098 ココカラファイン 390963 286311 90939 158179 ドラッグストア… DrugStore ## 6 3141 ウエルシアホールディングス… 695268 485320 181121 292238 ドラッグストア… DrugStore 4.4 財務指標の作成 それでは，結合したデータセットをもとに，家電業界とドラッグストア業界の財務指標を比較してみよう。 今回は2つの業界で収益性を比較する。 企業の収益性を比較するには，どうしたらよいだろうか。 最も単純な方法は，企業がビジネスで稼いだ利益を比較することだろう。 企業がビジネスで稼いだ利益は営業利益とよばれる。 しかし，企業の収益性を測るために，営業利益の金額を比較するのは不適切なことが多い。 なぜなら，企業間での規模の違いを無視しているからである。 営業利益が同じ10億円の企業でも，1,000億円の使用資本で1億円を稼いだ企業と，10億円の使用資本で1億円を稼いだ企業では，後者の方が明らかに効率の良い稼ぎ方をしている。 そこで，「使用資本に対して何%の利益を稼いだか」を表す財務指標を作成し，企業の収益性を分析するのがROAやROICといった財務指標である。いずれの指標も「利益/使用資本」で計算される指標だ。 なお，分母や分子にどの利益や使用資本をもってくるのかには様々な考え方がある。 本章では，これらのトピックについては深入りせず，R上で指標を計算する方法と簡単な解説のみを行う。 まずは，ROAを計算してみよう。ROAの値は最もコードの書きやすい「営業利益/期末資産」という式で計算し，データセットにROAの列を追加してみよう。 データセットに新しく列を追加するには，先ほども利用したmutate()関数を使う。 以下のコードでは，まず営業利益（ope_inc）を追加したうえで，ROAを営業利益にもとづいて計算し追加している。 # 変数の作成 df_2 &lt;- df_2 %&gt;% mutate( ope_inc = sales - (cogs + sga), roa = ope_inc / asset ) # 変数を指定してデータの確認 df_2 %&gt;% select( &quot;name&quot;, &quot;ope_inc&quot;, &quot;roa&quot;, &quot;ind&quot; ) %&gt;% head() ## # A tibble: 6 x 4 ## name ope_inc roa ind ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 カワチ薬品 4574 0.0250 ドラッグストア ## 2 エディオン 15379 0.0416 家電 ## 3 ビックカメラ 27057 0.0740 家電 ## 4 マツモトキヨシホールディングス 33567 0.107 ドラッグストア ## 5 ココカラファイン 13713 0.0867 ドラッグストア ## 6 ウエルシアホールディングス 28827 0.0986 ドラッグストア ここで，ROAを両業界で比較したいとする。 どう比較すればよいだろうか。 データを見た感じでは，なんとなくドラッグストアの方がROAは高い気もする。 しかし，ドラッグストアの方が「どれだけ高いか」は人によって判断が異なるだろう。 このような主観性を排除してデータの特徴を理解し，他人にも共有できる表現にするためには，「共通のモノサシ」が必要となる。 そこで共通のモノサシとして記述統計量がもちいられる。 記述統計量は平均値や分散など複数の指標を組み合わせてデータの特徴を表現する。 これらの指標は，大きく分けて2つのカテゴリーに分類できる。 2つのカテゴリーとは，データの中心的傾向の指標とデータのばらつきの指標である。 データの中心的傾向は，あるデータをまとめたとき，そのデータを代表する点がどの位置に存在するを示す。 平均値や中央値が中心的傾向の指標としてもちいられ，代表値ともよばれる。 一方，データのばらつきは，データが中心からどれだけバラついているかを示す。 ばらつきとして，分散や標準偏差という指標がもちいられる。 まず，データの中心的傾向の指標をみてみよう。 平均値（mean）は，観測値をすべて足し合わせた総和を，サンプルサイズで除することで計算される24。 平均値はデータの「重心」とも表現される。この表現は，1つだけ飛び抜けて高い値がある場合，平均値はこの飛び抜けて高い値に引っ張られることに起因している。シーソーに例えてみよう。各データをシーソーに乗せる重り，平均値をシーソーの支点と考える。このとき平均値はシーソーのバランスがちょうどとれる支点になる。この例えでいえば，シーソーの端っこにある重りの方が，支点の中心近くにある重りよりもシーソーを傾ける力が強い。そのため，１つの重りだけ端っこ近くにある場合，シーソーのバランスを取るために支点（平均値）をその重りのある端の方向へずらす必要がある。このように平均値は良くも悪くも飛び抜けて高い値の影響を受けることが特徴である。Rでは，mean()関数で計算できる。 中央値（median）は，観測値を大きさの順番に並べたとき，ちょうど中央に位置する観測値である。 平均値と中央値の違いは身長の例がわかりやすい。平均値はそのまま平均身長を表すのに対し，中央値は背の順で並んだときの「真ん中の人の身長」を表す。 平均値との違いは，１つだけ飛び抜けて高い値の影響を受けない点である。 例えば，１人だけ身長が飛び抜けて高い人物がいた場合，平均身長は高くなるものの，中央値はその値の影響を受けない。 なぜなら，１人だけ飛び抜けて高い人物がいたとしても背の順に並んだときの順番は変わらず，真ん中の人も同じだからだ。 このように飛び抜けて高い（もしくは低い）値の影響を排除して，全体的な傾向を把握したいときは中央値を使うことが望ましい。 Rでは，median()関数をもちいることで，中央値を計算できる。 中央値は，データをちょうど2分割にする区切りとみなすこともできる。 身長の例でいえば，データを背の低いグループと高いグループの半分半分で分けられるということだ。 実証的な会計研究では，データを4分割する区切りがよくもちいられる。 この区切りを四分位数（quantile）という。 それぞれの区切りは，小さい方から第1四分位数，第2四分位数，第3四分位数とよばれる。 例えば，クラスが100人いたとして背の順で並んでもらったとき，第1四分位数は前から25番目の人の身長，第2四分位数は前から50番目の人の身長，第3四分位数の人は前から75番目の人の身長となる。 もちろん第2四分位数は，中央値と等しくなる。四分位数にはquantile()関数がもちいられる。 統計的分析では，四分位点だけでなくデータを順に並べた際の両端の数，すなわち最も小さな数である最小値（minimum）と，最も大きな数である最大値（maximum）を確認する場合もある。 身長の例でいえば，背の順で並んだとき一番前の人の身長が最小値，一番後ろの人の身長が最大値である。 最小値と最大値を確認することで，データ全体の範囲やデータに極端な値が含まれているかどうかがチェックできる。 Rでは，最小値はmin()関数，最大値はmax()関数で算出できる。 次にデータのばらつきを示す指標を確認しよう。 データのばらつきを示す指標として，まず分散（variance）がある。 分散はデータの中心（平均値）から各観測値がどれだけ離れているかを示す偏差を2乗し，それをサンプルサイズで割ると求まる。 二乗をとる利用は，ばらつきには上にばらつく場合（平均値との差がプラス）と下にばらつく場合（平均値との差がマイナス）の2つのパターンがあるからだ。 どちらも平均値からばらついていることには代わりがない。 どちらのばらつきもプラスに変換するために二乗をとっていると考えてもらってよい。 分散をみることで，データの平均的なばらつきの程度をみることができる。 var()関数により計算される25。 しかし，分散の値でそのまま議論するのを好ましくないと判断するケースもある。 それは単位を問題にする場合である。 分散は偏差の「2乗」を観測値の数で割っている。 たとえば，売上高の分散を計算すると，その単位は「円\\(^2\\)」となる。 一方，売上高の平均値や中央値も同様に計算すると，単位が「円」となってしまう。 つまり，分散は平均値や中央値よりも2乗分大きく計算される。 これでは数字の大きさをすぐに理解することができないので，分散の単位を平均値や中央値とそろえる必要がある。 そこでもちいられるのが，分散の平方根をとった標準偏差 (standard deviation) である。 Rではsqrt()関数で計算される。 それでは，ROAの記述統計量を家電業界とドラッグストア業界で比較してみよう。 グループごとの記述統計量を出力するには，まずgroup_by()関数でどのグループに分けたいか指定し，summarise()関数で記述統計量を出力する 。今回は，両業界の中央値を比較してみよう。 なお平均値，四分位数，標準偏差といった他の指標もこれと同様の方法で出力できる。 # ROAの比較 df_2 %&gt;% group_by(ind) %&gt;% summarise(median(roa)) ## # A tibble: 2 x 2 ## ind `median(roa)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 ドラッグストア 0.103 ## 2 家電 0.0465 出力された各業界におけるROAの中央値をみてみると，ドラッグストアは0.103で，家電量販店0.0465となっており，両業界で約2倍ほど収益性が異なる。 なぜ，両業界でROAがこれほど異なるのだろうか。 これを調べるために，ROAの分解公式を利用してみよう。 ROAは売上高を挟むことで，「ROA \\(=\\) 利益/売上高 \\(\\times\\) 売上高/資産」と分解できる。 右辺の第1項を利益率，右辺の第2項を回転率とよぶ。 この分解公式は，企業がどのような要因で収益性を高めているかを分析するのに役立つ。 例えば，薄利多売のようなビジネスモデルの場合は，利益率が低い一方で回転率が高くなる。 反対に，高級品を少量販売するようなビジネスの場合，利益率が高くなる一方で回転率が低くなる。 この分解公式の各項目を計算して，業界間で比較したのが下記コードである。 複数列に対して同じ記述統計量を出力するには，summarise_at()関数が便利だ。 引数のvarsは，どの変数について記述統計量を出力するかを示している。 # 利益率と回転率の比較 df_2 %&gt;% mutate( margin = ope_inc / sales, turnover = sales / asset ) %&gt;% group_by(ind) %&gt;% summarise_at( vars(margin, turnover), median ) ## # A tibble: 2 x 3 ## ind margin turnover ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ドラッグストア 0.0529 2.10 ## 2 家電 0.0247 1.89 分析結果を確認してみると，回転率はドラッグストアが2.10，家電量販店が1.89と両業界でそれほど変わらないものの，利益率はドラッグストアが0.0529，家電量販店が0.0247と2倍近い差がついている。 すなわち，2つの業界におけるROAの中央値が2倍近く異なるのは，利益率が2倍近く異なるからだとわかる。 なぜ，両業界で利益率がこんなにも異なるのだろうか。 家電量販店業界の利益率の低さは，家電量販店がインターネット通販等に対抗するため「行きすぎた安売り」を行っている。 そのため，家電量販店の利益率が低くなっているいうのは想像がつくだろう。 一方，ドラッグストアも活用品や食料品販売などの値引き販売を行っているイメージが強いかもしれない。 しかし，ドラッグストアの場合は売上全体の約2割を占める医薬品の利益率が4割と非常に高い。 そのため，両業界で利益率に大きく差がでる。 このように，どちらの業界も値引き販売のイメージが強い業界ではあるものの，実際に会計データを利用して分析してみると，イメージとは違った現実が見えてくる。 Rに初期実装されている関数にread.csv()関数というものがある。これはread_csv()関数と同様にcsvファイルを読み込むための関数である。read.csv()関数を使っても同様の操作はできるものの，csvファイルのサイズが大きくなるとread_csv()関数の方がファイルの読み込みが早い。↩︎ データフレームの結合で，両データフレームに同じ名前の変数がある場合には，列名の重複を避けるためRが自動的に変数名.xと変数名.yという2つの変数を作成してしまうので注意。↩︎ サンプルの大きさのことをさす。本章でもちいているデータは20社の観測値から構成されるため，サンプルサイズは20となる。なお，「サンプル数」という言葉でサンプルの大きさが示されることがある。しかし，サンプル数は観察されたサンプルの群数を表すため，誤用が多い。たとえば，業界Aの売上高と業界Bの売上高が手元にあるなら，サンプル数が2つあると表現できる。↩︎ var()で計算される分散は，正確には「不偏分散」になる。以下で議論するsqrt()でも「不偏標準偏差」が計算される。↩︎ "],["05-会計情報の可視化.html", "Chapter 5 会計情報の可視化 5.1 この章について 5.2 1つのグラフを出力する 5.3 複数のグラフを出力する", " Chapter 5 会計情報の可視化 &lt;学習目標&gt; ・作成した財務数値のヒストグラム，散布図，箱ひげ図が出力できる ・複数の異なる財務指標のグラフを並べて表示できる 【応用例】 業界間での収益性指標の傾向を可視化できる 財務指標間の違いをグラフで可視化して確認する 【関連する会計研究】 Burgstahler D. and I. Dichev (1997) Earnings management to avoid earnings decreases and losses. Journal of Accounting and Economics, Vol. 24, No. 1, pp. 99–126. 5.1 この章について この章では，会計データの可視化について学習する。 第4章では，会計データの整頓方法について学習した。 そこでは，会計データに業界データを結合し，業界間で財務数値を比較できるようになった。 しかし，財務指標についてExcelのように並べられた生データを視るだけでは，データの傾向を把握することは難しい。 データの傾向を一目で理解するには，データをグラフとして出力し，可視化する必要がある。 会計データを可視化した代表的な研究として， Burgstahler and Dichev (1997) がある。 Burgstahler and Dichev (1997) は，企業の利益調整を統計的に検証した論文である。 彼らのもちいた検証方法は，利益分布アプローチとよばれている。 一般に，企業にとって前年度の利益は当年度の利益のベンチマークと考えられている。 新聞の見出しなどでも「連続増益」や「10%の減益」といった表現をよくみるだろう。 企業には，この前年度の利益を上回りたいというインセンティブが存在する。 この利益調整インセンティブを， Burgstahler and Dichev (1997) は会計データの可視化によって明らかにした。 図5.1をみてほしい。図5.1は， Burgstahler and Dichev (1997) が米国企業のデータをもちいて，当年度利益と前年度利益の差（\\(Earnings_t - Earnings_{t-1}\\)）をヒストグラムで可視化したものである26。 図5.1の0.00付近，すなわち当年度利益が前年度利益と同じ値になる付近を境に分布が不自然に歪んでいることがわかるだろう。 この分布の歪みは，前年度利益というベンチマークを上回るために，企業が利益調整をした証拠だとされている。 このようにデータの特徴を集約し，瞬時に理解を促すグラフは，企業行動の証拠を提示する強力なツールとなる。 Figure 5.1: Burgstahler and Dichev (1997, 105) この章では，まず財務指標を1つのグラフに出力する方法について学ぶ。 具体的には，4章で出力したROAをもとに，ヒストグラム・散布図・箱ひげ図といった統計学でよく使用されるグラフを出力する。 これらのグラフを利用することで，会計データの特徴や業界間の違いを一目で捉えられるようになるだろう。 また，複数のグラフを並べて出力する方法についても学習する。 この方法は，財務指標間の違いを比較したいときにも役立つ。 たとえば，収益性指標にもROA，ROE，ROICといった指標が存在する。 これらの収益性指標は，分子にどの利益を使うのか（たとえば，営業利益，経常利益，当期純利益），分母にどの使用資本を使うのか（たとえば，期首期末平均資産，期首資産）によって，様々なパターンが存在する。 同じデータセット内で，こうした複数の収益性指標の違いを一目で把握したい場合，ここで学習する内容が役立つだろう。 5.2 1つのグラフを出力する それでは，分析に利用する会計データを読み込んでみよう。 データは，4章で用いたものと同じであり，それらを4章と同様のやり方で加工している。わからない人は4章を復習しよう。 下記のコードの最後の部分では，前章までで学習したROA，利益率，回転率の中央値をそれぞれ出力している。 # パッケージの読み込み library(tidyverse) # データの読み込み df_0 &lt;- read_csv(&quot;data.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## ## ─ Column specification ──────────────────────────── ## cols( ## id = col_double(), ## name = col_character(), ## sales = col_double(), ## cogs = col_double(), ## sga = col_double(), ## asset = col_double(), ## debt = col_double(), ## equity = col_double(), ## receivable = col_double(), ## inventory = col_double(), ## payable = col_double(), ## tax = col_double(), ## ind = col_character(), ## ope_inc = col_double(), ## roa = col_double(), ## margin = col_double(), ## turnover = col_double(), ## employees = col_double() ## ) # データの確認 df_0 %&gt;% group_by(ind) %&gt;% summarise_at( vars(roa, margin, turnover), median ) ## # A tibble: 2 x 4 ## ind roa margin turnover ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 DrugStore 0.103 0.0529 2.10 ## 2 ElectronicsRetail 0.0465 0.0247 1.89 分析結果は前章と同じくROAについて，ドラッグストア業界は家電量販店業界の2倍近い値をとっている。 回転率・利益率も同じで，回転率については両業界でそれほど変わらないものの，利益率についてはドラッグトアが家電量販店の2倍近い値をとっている。 これらの結果から，ドラッグストア業界と家電量販店業界におけるROAの差は，回転率よりも利益率によって生じていると予測される。 この点を深堀りするため，散布図を出力して可視化してみよう。 グラフを出力したいときには，ggplot2パッケージを利用する。 このggplot2では，実行したい操作を順番に「+」でつないでコードを記述する。 コードの意味を理解しやすいよう，操作ごとにグラフを出力したものが下記のコードである。 なお，ggplot2はtidyverseに含まれているため，tidyverseを読み込んでいる場合はggplot2の読み込みを省略できる。 5.2.1 ggplotの記述方法 まず，ggplot( aes(x = margin, y = roa)というコードで，「いまからデータdf_0について，\\(x\\)軸を利益率，\\(y\\)軸をROAとしたグラフを書きます」と指定し，「margin_roa」という変数に代入する。 試しに「margin_roa」を出力してみると，\\(x\\)軸を利益率，\\(y\\)軸をROAとした表が出力される。 # ggolot2の設定 library(ggplot2) margin_roa &lt;- df_0 %&gt;% ggplot(aes(x = margin, y = roa)) margin_roa ここから，margin_roaに+で実行したい操作を記述し，表にグラフを書きこんでいく。 散布図を書き込むには，geom_point()関数を使う。 第章で学習する回帰直線を書き込みたい場合，stat_smooth()関数を使う。 引数には線形モデル(lm)を指定しよう。 このように+で操作を書き込むことで，グラフの追加ができる。 グラフの青い直線が回帰直線で，濃いグレーの範囲は95%信頼区間である。 信頼区間を表示させたくない場合は，stat_smooth(method = lm, se =FALSE)とする。 # 散布図 margin_roa + geom_point() margin_roa + geom_point() + stat_smooth(method = lm, se =FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; margin_roa + geom_point() + stat_smooth(method = lm) ## `geom_smooth()` using formula &#39;y ~ x&#39; 色や表示方法を変えたい場合は，引数の設定を変えることで調整できる。 例えば，業界ごとに色分けしたい場合は，ggplot(df_0, aes(x = margin, y = roa, color = ind)とすればよい。 描きたいグラフに合わせて色々と使い分けてみてほしい。 なお，ggplotのコードの書き方には，上記のような記述方法の他に，グラフを変数に代入して記述する方法もある。 下記では，業界ごとに色分けしたグラフを，変数に代入する記述方法で出力している。 コードを理解しやすいように，各グラフに別々の名前を設定している。 面倒なら，同じ名前をつかってどんどん上書きしていっても構わない。 # 代入による記入方法 margin_roa_color_ind &lt;- df_0 %&gt;% ggplot(aes(x = margin, y = roa, color = ind)) margin_roa_color_ind_point &lt;- margin_roa_color_ind + geom_point() margin_roa_color_ind_point_lm &lt;- margin_roa_color_ind_point + stat_smooth(method = lm) margin_roa_color_ind_point_lm ## `geom_smooth()` using formula &#39;y ~ x&#39; なお，上記のコードと同様の出力を下記のコードでも実行できる。 グラフの名前は慣例としてgを使う。 グラフの調整方法をインターネットで調べる場合は，こちらの記述方法が記載されていることが多い。 # gをつかった記入方法 g &lt;- df_0 %&gt;% ggplot(aes(x = margin, y = roa, color = ind)) + geom_point() + stat_smooth(method = lm) g ## `geom_smooth()` using formula &#39;y ~ x&#39; 5.2.2 ヒストグラムと箱ひげ図 ggplot2パッケージの記述方法が理解できたところで，ヒストグラムと箱ひげ図の出力をしてみよう。 このデータで，ROAの違いの大部分は利益率の違いだった。 そこで，2つの業界で，利益率がどの程度異なるのかを，まずはヒストグラムを書いて可視化する。 ヒストグラムには，geom_histogram()関数を使う。 重なると見づらいので，並べて表示するdodgeの引数を設定し，ヒストグラムの幅を0.01に設定している。 なお，ggplotの最初の設定部分で，業界ごとにグラフを塗り分けるfill = indという引数を設定した。 # ヒストグラム margin_hist &lt;- df_0 %&gt;% ggplot(aes(x = margin, fill = ind)) + geom_histogram(position = &quot;dodge&quot;, binwidth = 0.01) margin_hist 上記のグラフから，このデータではドラッグストア業界の方が一般的に利益率は高いという傾向が見て取れる。 これらのグラフに業界平均を書き込みたい場合は，各業界の平均値を計算して，その値の縦線を書き込めばよい。 縦線を引くコードはgeom_vline()関数を使う。 なお，各業界の平均値を代入するコードが少し難しいが，章で学習したパイプ演算子の記述法に沿って解釈してほしい。 # 各業界におけるmarginの平均値を計算 roa_means &lt;- df_0 %&gt;% group_by(ind) %&gt;% summarise(mean(margin)) # 各業界の平均値を，それぞれDSmeanとERmeanに代入 DSmean &lt;- roa_means %&gt;% filter(ind ==&quot;DrugStore&quot;) %&gt;% select(&quot;mean(margin)&quot;) %&gt;% as.numeric() ERmean &lt;- roa_means %&gt;% filter(ind ==&quot;ElectronicsRetail&quot;) %&gt;% select(&quot;mean(margin)&quot;) %&gt;% as.numeric() # 各業界の平均値をもとに縦線を書き込む margin_hist + geom_vline(xintercept=DSmean, color=&quot;red&quot;) + geom_vline(xintercept=ERmean, color=&quot;blue&quot;) もう少し要約したグラフが見たいときには，箱ひげ図が便利である。 箱ひげ図は，文字通り箱にひげが生えたようなグラフである。 箱ひげ図の出力には，geom_boxplot()関数を使う。 # 箱ひげ図 margin_box &lt;- df_0 %&gt;% ggplot(aes(x = ind, y = margin)) + geom_boxplot() margin_box 上記のグラフを参考に，箱ひげ図について説明する。 まず，箱ひげ図の箱にあたる部分に注目しよう。 グラフ左側にあるドラッグストアの箱では，箱の上辺が0.06あたりで，下辺が0.04あたりをとっている。 この上辺の値はサンプル全体の上位25%にあたるデータの数値であり，下辺の値はサンプル全体の上位75%にあたるデータの数値である。 箱の内部にある線は，上位50%にあたるデータの数値（中央値）である。 このように，この箱の位置や長さからデータの分布を読み取ることができる。 なお，ひげにあたる部分は，分布の上限および下限を示している。 厳密には，このひげの長さの決め方には様々な方法があるものの，箱の高さ(IQR:interquartile range)に1.5をかけた範囲内で最も高い（下境界の場合は低い）データの値とするのが一般的であり，ggplotもこの方法で計算されている。 5.2.3 折れ線グラフ 折れ線グラフの作成方法について解説する。 折れ線グラフには，geom_line()関数を使う。 折れ線グラフは，時系列での変化を可視化する目的で利用される。 「data.csv」は単一年度のデータなので，通常，このデータから折れ線グラフを作成することはない。 そこで，折れ線グラフの作成方法を理解するために，「data.csv」から時系列データを便宜的に作成する。 そのために，時系列を意味する変数timeをrow_number()関数により作成する。 この関数はデータの行番号を返す関数で，1行目のデータ（カワチ薬品）には1，2行目のデータ（エディオン）には2が返される。 df_0は18企業のデータが収録されているため，変数timeは1〜18までの整数となる。 では，変数timeを横軸，変数salesを縦軸として，折れ線グラフを作成しよう。 # 時系列変数の作成 df_0 &lt;- df_0 %&gt;% mutate(time = row_number()) head(df_0) ## # A tibble: 6 x 19 ## id name sales cogs sga asset debt equity receivable inventory ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 32019 91880 3073 29846 ## 2 2730 エディオン 686284 488119 182786 369547 65930 169005 34530 111703 ## 3 3048 ビックカメラ… 844029 607947 209025 365605 95576 155765 32968 106731 ## 4 3088 マツモトキヨシホー… 558879 389673 135639 315161 0 204871 20905 70362 ## 5 3098 ココカラファイン… 390963 286311 90939 158179 300 87810 20329 46522 ## 6 3141 ウエルシアホールデ… 695268 485320 181121 292238 44225 130482 23514 76317 ## # … with 9 more variables: payable &lt;dbl&gt;, tax &lt;dbl&gt;, ind &lt;chr&gt;, ope_inc &lt;dbl&gt;, ## # roa &lt;dbl&gt;, margin &lt;dbl&gt;, turnover &lt;dbl&gt;, employees &lt;dbl&gt;, time &lt;int&gt; # 折れ線 margin_line &lt;- df_0 %&gt;% ggplot(aes(x = time, y = sales)) + geom_line() margin_line 続いて，複数の線の折れ線グラフを作成する方法を説明する。 今度は，業種ごとにグループ化した後に変数timeを作成する。 この処理により，そのデータが業種内で何番目に収録されているかが返ってくる。 すなわち，ドラッグストアの中で一番上にあるカワチ薬品には1，家電量販店の中で一番上にあるエディオンには1が返される。 そして，ドラッグストアの中で2番目にあるマツモトキヨシホールディングスには2，家電量販店の中で2番目にあるビックカメラには2が返される。 df_0はドラッグストア9社，家電量販点9社のデータが収録されているため，変数timeは1〜9までの整数が2個ずつ存在する。 では，変数timeを横軸，変数salesを縦軸として，産業ごとの折れ線グラフを作成しよう。 複数の線の折れ線グラフを作成するには，各折れ線を識別する必要がある。 識別方法は2つあり，1つは線の色による識別で，もう１つは線のスタイルによる識別である。 線の色により識別する場合，aes(x = time, y = sales, colour = ind)とする。 ドラッグストアの折れ線は赤色に，家電量販点の折れ線は緑色になった。 線のスタイルにより識別する場合，aes(x = time, y = sales, linetype = ind)とする。 ドラッグストアの折れ線は実線に，家電量販点の折れ線は点線になった。 # 時系列変数の作成 df_0 &lt;- df_0 %&gt;% group_by(ind) %&gt;% mutate(time = row_number()) head(df_0) ## # A tibble: 6 x 19 ## # Groups: ind [2] ## id name sales cogs sga asset debt equity receivable inventory ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 32019 91880 3073 29846 ## 2 2730 エディオン 686284 488119 182786 369547 65930 169005 34530 111703 ## 3 3048 ビックカメラ… 844029 607947 209025 365605 95576 155765 32968 106731 ## 4 3088 マツモトキヨシホー… 558879 389673 135639 315161 0 204871 20905 70362 ## 5 3098 ココカラファイン… 390963 286311 90939 158179 300 87810 20329 46522 ## 6 3141 ウエルシアホールデ… 695268 485320 181121 292238 44225 130482 23514 76317 ## # … with 9 more variables: payable &lt;dbl&gt;, tax &lt;dbl&gt;, ind &lt;chr&gt;, ope_inc &lt;dbl&gt;, ## # roa &lt;dbl&gt;, margin &lt;dbl&gt;, turnover &lt;dbl&gt;, employees &lt;dbl&gt;, time &lt;int&gt; # 折れ線（線の色による識別） margin_line &lt;- df_0 %&gt;% ggplot(aes(x = time, y = sales, colour = ind)) + geom_line() margin_line # 折れ線（線のスタイルによる識別） margin_line &lt;- df_0 %&gt;% ggplot(aes(x = time, y = sales, linetype = ind)) + geom_line() margin_line 5.3 複数のグラフを出力する それでは複数のグラフを出力する方法について学習しよう。 この方法は同じデータセット内で複数の財務指標を比較したいときに役立つ。 なお，この節には高度な内容が含まれるため，初学者は読み飛ばしてもらっても構わない。 これまでの収益性指標であるROAに加えて，新しくROIC(Return on Investment Capital)を取扱うことにしよう。 ROICは運転資本の要素を考慮した収益性指標である。 運転資本とは，材料調達・製品製造・製品販売・代金回収というビジネスのサイクルを回すのに必要な資本である。 運転資本は「運転資本 \\(=\\) 棚卸資産 \\(+\\) 売上債権 \\(-\\) 仕入債務」という式で計算される27。 運転資本は，企業の資金繰りと非常に関連の深い指標だが，企業の資金繰りをより直接的に表す指標として，CCC(Cash Conversion Cycle)という財務指標も存在する。 CCCは「CCC \\(=\\) 売上債権/売上高 \\(+\\) 棚卸資産/売上原価 \\(+\\) 仕入債務/売上原価」と計算される。 CCCは，企業が原材料や商品仕入などで現金を投入してから，最終的に現金化されるまでの平均日数を示している。 この運転資本とCCCについて，ドラッグストアと家電量販店を比べてみよう。 まずは，それぞれの変数を作成し，グラフを作成する。 # 変数作成 df_0 &lt;- df_0 %&gt;% mutate( wc = inventory + receivable - payable, wcr = wc / asset, ccc = receivable / sales + inventory / cogs - payable / cogs ) # 運転資本のグラフ gwc &lt;- df_0 %&gt;% ggplot(aes(x = wcr, fill = ind)) + geom_histogram(position = &quot;dodge&quot;, binwidth = 0.05) # CCCのグラフ gccc &lt;- df_0 %&gt;% ggplot(aes(x = ccc, fill = ind)) + geom_histogram(position = &quot;dodge&quot;, binwidth = 0.05) 2つのグラフをまとめて出力するには，gridExtraパッケージのgrid.arrange()関数を利用する。 # 2つのグラフを並べて表示 # install.packages(&quot;gridExtra&quot;) library(gridExtra) ## ## Attaching package: &#39;gridExtra&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## combine grid.arrange(gwc, gccc, ncol = 1) グラフから運転資本とCCCの両方で，家電量販店の方がドラッグストアより高い。 この分析結果は，家電量販店業界の方がドラッグストア業界に比べて，キャッシュとして回収されるまでのスピードが遅く，ビジネスを回すのに必要な資金（運転資本）が多いことを示している。 この2つの業界における違いは，両者のビジネス・モデルを想像してもらえば，理解しやすいだろう。 製品自体の単価が高く，消費者が購入するタイミングも限られている家電に比べて，商品の単価が低く，消費者が日常的に購入する食料品や医薬品を仕入れて売る方が，必要な資金も，現金化するまでの日数も短い。 こうした資金繰りの違いを加味した収益性指標がROICである。 ROICは，固定資産などの資産に運転資本を含めた投下資本全体に対して何%の利益を上げたかを表す指標であり，「ROIC \\(=\\) 利益 / 投下資本」で計算される。 投下資本は2種類の計算方法があり，貸借対照表の貸方(運用サイド)では「投下資本 \\(=\\) 運転資本 \\(+\\) 固定資産など」，貸借対照表の借方(調達サイド)では「投下資本 \\(=\\) 有利子負債 \\(+\\) 純資産」と計算できる。 貸借対照表の性質から2つの計算方法の結果は一致する。 ROAとの違いは，上述した資金繰りの違いをROICの方が反映できる点である。 たとえば，資産全体の額が変わらないまま，仕入債務の割合が増加したとしよう。 すなわち，購入したモノの支払いを遅らせることができ，キャッシュに余裕が生じている状態である。 いま，その余裕ができた分を，借入金の返済にあてたとしよう。 このとき，資産全体の額は変化しないのでROAには変化がない。 しかし，運転資本は減少しているため，ROICの値は改善される。 このように，ROICは企業の資金繰りの良し悪しを加味した収益性評価ができる。 ROICの分子には，NOPAT（Net Operating Profit After Tax）とよばれる値を持ってくる。 NOPATの定義は論者によって微妙に異なる。 ここでは，簡便的に税引き後営業利益を利用する。 営業利益から税金を考慮する理由は，本業で稼いだ利益のうち，資金提供者間で分配可能な金額はいくらか知りたいからである。 それでは，ROICを計算してみよう。 ここでは，「ROIC \\(=\\) (営業利益 \\(-\\) 法人税) / (有利子負債 \\(+\\) 純資産)」で計算する。 なお，ROICの特徴を理解するため，ROAの分析結果と比較したい。 しかし，ROICとROAでは分子と分母の両方が異なるため，ROICとROAを直接比較しても，分子と分母のどちらの影響を受けたのか分かりづらい。 そこで，「分子を税引後営業利益にしたROA」と「分子を営業利益にしたROIC」も作成し，これらの結果を比較してみよう。 これまでと同様にggplotを使い，今回は2 \\(\\times\\) 2の表で表示する。 表を分割するには，facet_wrap()関数を使い，引数にはどの列名で分割するのか，何行で表示するのかを指定する。 グラフを出力するために，gather()関数をもちいて，整然データの形式に修正している点に注意してほしい。 なお，gather()関数についてはweb付録を参照すること。 # 変数作成 df_0 &lt;- df_0 %&gt;% mutate( roa = ope_inc / asset, roa_nopat = (ope_inc - tax) / asset, roic_ope = ope_inc / (debt + equity), roic = (ope_inc - tax) / (debt + equity) ) # グラフ作成用の整然データを作成 df_1 &lt;- df_0 %&gt;% select( id, roa, roa_nopat, roic_ope, roic, ind ) %&gt;% gather( measure, value, -id, -ind ) # 4つのグラフを2*2で表示(gをつかった記入方法) g &lt;- df_1 %&gt;% ggplot(aes(x = value, fill = ind)) + geom_histogram( position = &quot;identity&quot;, alpha = 0.8, binwidth = 0.01 ) + facet_wrap(~measure, nrow = 2) + xlab(&quot;[Operating Profit] VS [Operating Profit minus Taxes]&quot;) + ylab(&quot;[ROIC] VS [ROA]&quot;) g グラフでは，上段は分母に資産を用いた収益性指標，下段は分母に投下資本をもちいた収益性指標を表している。 一方で，左列は分子に営業利益を用いた収益性指標，右列は分子に税引き後営業利益を用いら収益性指標を表している。 まず，上下を見比べると，下段の2つのグラフの方がドラッグストアと家電量販店の差は大きい。 この差は分母に投下資本をもちいたことで，ドラッグストアの資金繰りの良さがより顕著に反映されたことを意味している。 一方，左右2つのグラフを見比べると，税引き後営業利益の結果の方が，ドラッグストアと家電量販店の差は小さいとわかる。 この違いは，ドラッグストアの方が多くの法人税を支払っていることを意味している。 法人税は企業が獲得した利益をベースに決定される。 そのため，資本効率性の高いドラッグストアの方が，ROAおよびROICに比して高い税金を支払っているためだと考えられる。 利益差をそのまま使うと規模の影響が出るので，時価総額で基準化されている。↩︎ なお，各指標は期首・期末を平均化した値を用いることが一般的だが，本節ではコードの簡略化の観点から期末の値を用いた↩︎ "],["06-会計情報の検定.html", "Chapter 6 会計情報を検定する 6.1 この章について 6.2 用語説明 6.3 t検定", " Chapter 6 会計情報を検定する &lt;学習目標&gt; ・t検定と相関の検定について理解する ・RStudionを利用して，それぞれの検定を実施できる 【応用例】 なし 【関連する会計研究】 なし 6.1 この章について 前章では，(1) 平均や分散といった記述統計量の意味，(2) それらの記述統計量をRStudioにより算出する方法，(3) データをヒストグラムなどにより視覚的に示す方法を学習した。 しかしながら，多くの会計研究では，収集したデータから記述統計量を算出するだけではなく，これらを応用した統計分析により仮説検証が行われる。 本章では，その中でも基本的な統計分析であるt検定と相関の検定の2つを紹介し，RStudioでそれらを実行する方法について説明する。 6.2 用語説明 6.2.1 母集団と標本 母集団とは，「これから知りたいと思う集団全体」である。 一方で，標本（サンプルとも呼ばれる）とは，「母集団から分析のために選び出された要素」である。 統計分析を行う主要な目的の1つに，標本のデータを利用して母集団について知るというものがある。 以下の状況について考えてみよう。 あなたは精密機器の部品を製造する工場長である。 この工場では，製品Aを大量生産している。 あなたはそれが設計値どおりに製造されているかどうかを確認するという品質管理の業務を任されている。 確認しなければいけない項目は多々あるが，その中の1つに重量がある。 製品Aの重量は設計値では50gとされている。 しかしながら，様々な要因により，実際に製造された個々の製品の重量と設計値との間には差異が発生する。 そのため，個々の製品の重量は厳密に50gである必要はないものの，差異は許容の範囲内に収まっている必要がある。 差異が許容範囲内かどうかを確かめるために，非常に多くの労力をかけて全ての製品Aの重量を測定するのは，品質管理の方法として現実的では無い。 なぜなら，あなたの仕事は製品Aの重量を測定することだけでは無いし，それはあなたの部下も同様だからである。 仮に，製造された製品Aの中から幾つかの製品を抜き出し，それらのデータから「製品Aが設計値どおりの重量で製造されているとみなせるかどうか」を推定できるならば，品質管理にかかる労力は大幅に削減され現実に遂行可能な方法となる。 これを可能とするのが統計分析である。 統計分析により，標本のデータから母集団の統計的な特徴を推定できる。 すなわち，製造された製品Aの中から幾つかを抽出して標本とし，それらの重量を測定することで，母集団である製造したすべての製品Aの重量の特徴を推定できる。 6.2.2 有意水準 統計分析では，標本から算出される平均や分散を用いて，母集団の平均や分散が特定の値と異なるかどうかを判断する。 製品Aについて，重量の平均値が50gの場合に設計値どおりの重量で製造されているとみなす。 しかしながら，実際の製品Aの重量における平均値は厳密には50gとならず，差異が生じる。 重要なことは，それが誤差の範囲内とみなせるものか，それとも誤差の範囲内とはみなせないものか，ということである。 後者の場合，統計学では有意であるという。 実際の製品Aの重量について50gと有意に差があるという結果が得られた場合，製品Aは設計値どおりに製造されたとはいえない。 統計分析で得られる結果は，母集団の平均値や分散が特定の値であると仮定した場合に，標本の平均値や分散がその値をとる蓋然性だといえる。 そして，蓋然性が高い結果である場合は誤差の範囲内と判断し，低い場合には有意であると判断する。 有意水準とは，有意な差とみなすどうかを判断する基準である。 有意水準は5%や1%などのように%で設定される。 ここで，有意水準をどの値に設定するかという問題が生じる。 これは，その研究や分析の目的，先行研究の慣行などで異なる。 会計研究の場合は，10%，5%，1%という3つの基準を用いる場合と，5%，1%，0.1%という3つの基準を用いる場合が多い。 6.3 t検定 まずは，t検定とよばれる統計分析を紹介する。 t検定は平均値に関する統計分析で利用される。 では，平均値に関する統計分析はどのような場合に行われるのか。 大きく分けて2つの場合がある。 1つは，標本のデータにおける平均値と特定の値とを比較し，それらが異なる値かどうかを確かめる場合。 もう1つは，手元に2種類の標本が存在し，それらの平均値が異なるかどうかを確かめる場合である。 前者の場合に行うt検定は「一群のt検定」とよばれ，後者の場合に行うt検定は「二群のt検定」とよばれる。 「二群のt検定」はさらに2種類に分類できる。 1つは，2つの母集団の比較を行う場合で，もう1つは，同一母集団から得られた対応のある2データを比較する場合である。 前者は「対応のない二群のt検定」とよばれ，後者は「対応のある二群のt検定」とよばれる。 本章では「対応のない二群のt検定」をRで実行する方法について説明する。 なお，「一群のt検定」と「対応のある二群のt検定」をRStudioで実行する方法については巻末で説明している。 6.3.1 対応のない二群のt検定 対応のない二群のt検定では，2つの母集団を比較する。 たとえば，異なる業種間で利益額や売上高成長率などの会計数値に差があるかを調べたいとする。 このような場合には，対応のない二群のt検定を用いればよい。 ドラッグストアと家電量販店の2業種でROAに差があるかどうかを調べるために，対応のない二群のt検定を実行しよう。 データはdata.csvを利用する。 # パッケージの読み込み library(tidyverse) # データの読み込み df_0 &lt;- read_csv(&quot;data.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## ## ─ Column specification ──────────────────────────── ## cols( ## id = col_double(), ## name = col_character(), ## sales = col_double(), ## cogs = col_double(), ## sga = col_double(), ## asset = col_double(), ## debt = col_double(), ## equity = col_double(), ## receivable = col_double(), ## inventory = col_double(), ## payable = col_double(), ## tax = col_double(), ## ind = col_character(), ## ope_inc = col_double(), ## roa = col_double(), ## margin = col_double(), ## turnover = col_double(), ## employees = col_double() ## ) head(df_0) ## # A tibble: 6 x 18 ## id name sales cogs sga asset debt equity receivable inventory ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2664 カワチ薬品 268205 211068 52563 183303 32019 91880 3073 29846 ## 2 2730 エディオン 686284 488119 182786 369547 65930 169005 34530 111703 ## 3 3048 ビックカメラ… 844029 607947 209025 365605 95576 155765 32968 106731 ## 4 3088 マツモトキヨシホー… 558879 389673 135639 315161 0 204871 20905 70362 ## 5 3098 ココカラファイン… 390963 286311 90939 158179 300 87810 20329 46522 ## 6 3141 ウエルシアホールデ… 695268 485320 181121 292238 44225 130482 23514 76317 ## # … with 8 more variables: payable &lt;dbl&gt;, tax &lt;dbl&gt;, ind &lt;chr&gt;, ope_inc &lt;dbl&gt;, ## # roa &lt;dbl&gt;, margin &lt;dbl&gt;, turnover &lt;dbl&gt;, employees &lt;dbl&gt; まずは，業種別にROAの平均値を算出しよう。 この作業は2つのステップに分けることができる。まず，データを業種別にグループ化する。 続いて，グループごとに平均値を算出する。 最初のステップにはgroup_by()関数を利用する。 group_by()関数は，group_by(.data, ...)のように記述する。 .dataには対象となるデータフレームを記述する。 パイプ演算子%&gt;%により事前にデータフレームを指定している場合は，.dataの記述を省略する。 また，...にはどの変数に基づいてグループ化すればよいかを記述する。 ...は複数の変数を指定可能で，例えば，year，industry，prefectureの3変数によりグループ化したい場合には，group_by(df, year，industry，prefecture)と記述すれば良い。 したがって，最初のステップを実行するにはdf_0 %&gt;% group_by(ind)と記述すればよいとわかる。 続いて，summarise()関数を用いてグループごとに平均値を算出する。 summarise()関数は，summarise(.data, ...)のように記述する。 .dataには対象となるデータフレームを記述する。 summarise()関数についてもgroup_by()関数と同様で，.dataは，パイプ演算子%&gt;%で事前にデータフレームを指定している場合は省略する。 ...には，表示したい情報を算出するための処理を記入する。 書き方は，x = func()のように記述する。xは結果のラベルに表示したい名前，func()は処理方法を示している。 変数roaの平均値をroa_meanというラベルで算出したいならば，roa_mean = mean(roa)と記述する28。 したがって，2番目のステップを実行するにはsummarise(roa_mean = mean(roa))と記述すればよい。 業種別にROAの平均値を算出するという処理は，上記の2つのステップを連続処理したものなので，それらをパイプ演算子%&gt;%でつないで，df_0 %&gt;% group_by(ind) %&gt;% summarise(roa_mean = mean(roa))というコードを実行すればよい。 # 平均値の算出 df_0 %&gt;% group_by(ind) %&gt;% summarise(roa_mean = mean(roa)) ## # A tibble: 2 x 2 ## ind roa_mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 DrugStore 0.0991 ## 2 ElectronicsRetail 0.0482 結果を確認すると，ドラッグストアの企業ではROAの平均値が0.0991となった。一方で，家電量販店の企業ではROAの平均値が0.0482となっている。 つまり，ROAの業種平均値はドラッグストアの方が家電量販店よりも，高い数値を示している。 この2業種間の平均値の差が有意なものか確認するために，有意水準を5%として二群のt検定を実施してみよう。 Rでt検定を実行するには，t.test()関数を利用する。 変数xの平均値と変数yの平均値に有意な差があるかどうかを二群のt検定より検証する場合，t.test(x, y)と記せばよい。 今回はデータセットdf_0において，ドラッグストアの企業と家電量販店の企業とで，変数roaの平均値を比較する。 したがって，xはdf_0 %&gt;% filter(ind == \"DrugStore\") %&gt;% pull(roa)，yはdf_0 %&gt;% filter(ind == \"ElectronicsRetail\") %&gt;% pull(roa)とすればよい。 pull()関数は，データフレームに収録されている1変数をベクトルとして抜き出す関数である。 df_0 %&gt;% filter(ind == \"DrugStore\") %&gt;% pull(weight) %&gt;% pull(roa)は，データフレームdf_0に収録されているドラッグストア企業のデータのうち，roaという変数のみを抽出したことを意味する。 では，有意水準を5%として，対応のない二群のt検定を実施してみよう。 結果は以下のように表示されるはずである29。 今回の分析は「Welch Two Sample t-test」と記されている。 日本語では，ウェルチによる二群のt検定とよばれる30。対応のない二群のt検定は，通常この分析手法が採用される。 # 二群のt検定（対応なし） t.test( df_0 %&gt;% filter(ind == &quot;DrugStore&quot;) %&gt;% pull(roa), df_0 %&gt;% filter(ind == &quot;ElectronicsRetail&quot;) %&gt;% pull(roa) ) ## ## Welch Two Sample t-test ## ## data: df_0 %&gt;% filter(ind == &quot;DrugStore&quot;) %&gt;% pull(roa) and df_0 %&gt;% filter(ind == &quot;ElectronicsRetail&quot;) %&gt;% pull(roa) ## t = 3.8905, df = 16, p-value = 0.0013 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.02316547 0.07863742 ## sample estimates: ## mean of x mean of y ## 0.09909799 0.04819655 分析結果の下2行を確認すると，「mean of x 0.09909799」，「mean of y 0.04819655」と記されており，summarise()関数により平均値を確認した場合と同様の結果が得られている。 最後にp-valueを確認すると，5% (0.05) より小さな値となっている（p-value = 0.0013）。 よって，ドラッグストアの方が家電量販店よりもROAの業種平均値が高いと判断できる。 6.3.2 相関係数 二群のt検定は，2つの変数の平均値を比較する分析である。 しかしながら，我々が興味を持つ2変数間の関係は，平均値の差だけではない。 定量的な研究を含む多くのデータ分析では，変数間の関連性に興味がある場合も多い。 たとえば，「従業員満足度が高い企業は業績がよいのか」や，「今年度高い利益を計上した企業は来年度も高い利益を計上するか」などである。 このような変数間の関連性は相関関係とよばれる。ある変数が大きい（小さい）ときに，別の変数が大きい（小さい）という関係は，正の相関関係とよばれる 。一方，ある変数が大きい（小さい）ときに，別の変数が小さい（大きい）という関係は，負の相関関係とよばれる。 データフレームdf_0を用いて，企業の変数salesと変数sgaとの関連性について確認しよう。 売上高の変動に対して，販管費がどのように変動するのかについて，会計研究で盛んに研究されている。 この詳細については続く章で説明する。 ここでは簡単に両者の相関関係についてのみ確認しよう。 まずは，両者の相関関係を視覚的に確認するために，ggplot2パッケージを用いて散布図を描写する。 ggplot2はtidyverseに含まれている。 既にtidyverseを読み込んでいるため，ggplot2を読み込む必要はない。 散布図はgeom_point()関数を用いて描写できる。 # 散布図の描写 g &lt;- df_0 %&gt;% ggplot(aes(x = sales, y = sga)) + geom_point() g 表示された営業利益の散布図からは，変数salesと変数sgaには正の相関関係がみてとれる。 すなわち，売上高が高い企業は販管費も高いという関係が確認できる。 しかし，散布図は視覚的であるため，「どの程度の大きさの相関関係なのか」を客観的に把握できない。 そこで使用されるのが，相関係数という指標である。相関係数は，ある2変数間の相関関係を量的に表した指標である。 相関係数は−1から1の範囲の値をとり，正の値の場合は正の相関関係が，負の値をとる場合は負の相関関係があることを示している。また，値の絶対値が大きいほど相関関係が強いと，値が0に近いほど相関関係が弱いと判断できる。 では，Rで変数salesと変数sgaの相関係数を求めてみよう。 相関係数の算出にはcor()関数を用いる。 変数xと変数yの相関係数を算出するには，cor(x, y)と記す。 # 相関係数の算出 cor( df_0 %&gt;% pull(sales), df_0 %&gt;% pull(sga) ) ## [1] 0.9804564 変数salesと変数sgaの相関は0.980…であることが示された。 6.3.3 相関係数の検定 算出された相関係数が厳密に0と一致しない限り，相関係数の数値上は正か負の相関が存在している。 たとえば，相関係数が0.01の場合，僅かではあるが正の相関がある。 しかしながら，そのような僅かな相関関係は相関がないとみなしてよい程度かもしれない。 算出された相関係数が厳密に0となることは殆どないため，その値を0とみなしてよいかの判断が重要となる。 その判断のために，算出された相関係数が有意に0と異なるかどうかを検定する場合がある。 そのような検定は，相関係数の検定と呼ばれ，Rではcor.test()関数でできる。 変数xと変数yの相関係数について検定を行うには，cor.test(x, y)と書く。 先に利用した企業の利益に関するデータで，変数salesと変数sgaに相関があるかどうかを5%水準で検定しよう。 結果は以下のように表示される。多くの情報が表示されているが，特に確認しなければいけない情報は以下の3つである。 # 相関の分析 options(scipen=100) cor.test( df_0 %&gt;% pull(sales), df_0 %&gt;% pull(sga) ) ## ## Pearson&#39;s product-moment correlation ## ## data: df_0 %&gt;% pull(sales) and df_0 %&gt;% pull(sga) ## t = 19.934, df = 16, p-value = 0.000000000001007 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.9471319 0.9928525 ## sample estimates: ## cor ## 0.9804564 1つ目は，一番上に書かれている「Pearson’s product-moment correlation」という表記である。 これは，今回検定に利用した相関係数がピアソン (Pearson) の積率相関係数であることを意味する。 相関係数にはいくつか種類があるが，連続変数同士の相関係数を計算する場合，ピアソンの積率相関係数が利用される。 2つ目は，下2行に記された「cor0.9804564」という表記で，変数salesと変数sgaの相関係数を示している。 cor()関数により算出した場合と同じ結果が得られている。 最後に，p-value = 0.00…07となり，p値が5%よりも小さい値となった。 ここから，変数salesと変数sgaの間に有意に正の相関があると判断でき，売上高が高い企業は販管費も高い傾向にあるといえる。 ラベル名の指定は省略することもできる。その時は単にsummarise(df, mean(roa))と記述する。↩︎ t = 3.8905のtはt値，df = 16のdfは自由度を意味している。「95 percent confidence interval」は95%信頼区間を意味している。本章では，これらの詳しい説明については省略する。↩︎ ウェルチは人名で，この分析を提案した人物を指す。↩︎ "],["07-単回帰.html", "Chapter 7 単回帰分析とCVP分析 7.1 CVP分析とは 7.2 最小二乗法を利用した固変分解", " Chapter 7 単回帰分析とCVP分析 【応用例】 損益分岐点分析（CVP分析） 【関連する会計研究】 福嶋誠宣・新井康平 (2012) 「企業レベルでのコストビヘイビア推定」, 『Hirao School of Management Review』, Vol. 2, 1–7. 7.1 CVP分析とは CVP分析とは，コスト（Cost），売上高（Volume），利益（Profit）の相互関係（CVP関係ともいう）を用いて行われる分析のことをさす31。 ただし，データの入手の困難性から，CVP分析を行う際にはVolumeとして売上高が利用されることが多い。 これらの3つには「利益 \\(=\\) 売上高 \\(-\\) コスト」という関係がある。この関係をベースとして，さまざまな分析がなされる。 最も代表的な分析はCVP関係を基礎として行われる損益分岐点分析である。 ある調査によれば，CVP分析は6割強の企業で利用されており(吉田, 福島, and 妹尾 2017, 67)，実務的にも非常に重要な分析ツールである。 CVP分析は短期（会計分野では通常，1年以内）の利益計画を策定する際にその力を発揮する。 なぜなら，CVP分析では，売上高や販売量，コスト，および利益の関係について条件を変えてシミュレーションできるからである。 たとえば，来期の営業利益目標が100億円だった場合に，CVP分析を利用して目標となる売上高や販売量を計算できる。 また，企業努力によりコスト削減に成功した場合に，それが利益に与える影響を確かめることもできる。 ただし，企業が公表している財務会計に則った財務数値のみでは即座に，CVP分析を行うことはできない。 なぜなら，CVP分析を行うためには，コストを固定費と変動費に分類しなければならないからである。 そこで，本章では，CVP分析を行う際の固定費と変動費に関したコスト関数の推定方法を紹介する。 7.1.1 固定費と変動費 先述したように，CVP分析を行うは，コストを固定費と変動費に分けて考える。このコストの分類方法は原価を操業度の観点から分類している32。 固定費とは売上高に関連なく発生する原価のことをさす（図7.1：左側）。 たとえば，毎月定額支払わなければならない家賃や正社員に対する給料が固定費となる。 なぜなら，こうしたコストはたとえ製品が全く売れなくても，また工場が操業していなくても発生するからである。 一方，変動費とは，売上高に応じて変化する原価のことをさす（図7.1：右側）。 たとえば，製品を製造するための主要な材料が変動費になることが多い。 Figure 7.1: 固定費と変動費 それではなぜコストを固定費と変動費に分ける必要があるのだろうか。 コストを固定費と変動費に分解することによって，たとえば，売上高が2倍となった場合にコストがいくらになるかが判明し，それとともに利益がいくらになるかがわかる。 もし仮に，コストを固定費と変動費に分解できなければ，操業度や売上高が変化した際にコストがどれだけ変化するのかわからない。 すると，必然的に利益もいくら変化するかがわからなくなる。 したがって，CVP分析においてはコストを固定費と変動費に分解することが重要となる。 これによって，短期の利益計画の策定といった意思決定に有用な情報をもたらす。 固定費・変動費という2つのコスト概念を合わせると，企業の総コストは図7.2で表すことができる。 Figure 7.2: 総コスト ここで，コストを\\(y\\)，売上高を\\(x\\)と表現し，図7.2の総コストについて売上高を用いて数式で表現すると， \\[\\begin{align*} y=\\alpha +\\beta x, \\end{align*}\\] となる。 いま，\\(\\alpha\\)は固定費を，\\(\\beta\\)は変動費率を，\\(\\beta x\\)は変動費を表す。 図7.2にさらに売上高を表す直線を加えると，図7.3になる。 Figure 7.3: CVP関係 なお，総コスト線と売上高線が交わる点を損益分岐点という。 損益分岐点とは，総費用と売上高が一致しており，利益も損失もゼロとなる点である。 したがって，企業が利益を確保するためには，損益分岐点を超えるような売上高ないしは販売量を達成する必要がある。 総コスト線が求まることで，損益分岐点分析や目標利益を達成するために必要な売上高を求めるといったCVP分析が可能となる。 7.1.2 固変分解の方法 コストを固定費と変動費に分解する方法（固変分解ともいう）はいくつか存在する。本章ではとくにその中でも最小二乗法による固変分解に焦点を合わせるが，その前に他の固変分解の方法も紹介する。 勘定科目別精査法は過去の経験にもとづいて，コストを勘定科目ごとに固定費と変動費に分類する方法である。この方法は，費目別精査法ともよばれる。 また，スキャッター・チャート法はこれまでに実現した原価の実績データをグラフ化し，これらの点の真ん中を通る原価直線を目分量で引く方法である。 さらに，高低点法もスキャッター・チャート法と同様に，過去のある期間内における実績データを用いる。ただし，高低点法では，最高の営業量のときと最低の営業量のときの2点のデータを用いて，コストを営業量1単位あたりの変動費（変動費率）と固定費に分類する。このとき，変動費率と固定費はそれぞれ次のように計算される。 \\[\\begin{align*} &amp; \\mbox{変動費率}=\\frac{\\mbox{最高の売上高のときのコスト}-\\mbox{最低の売上高のときのコスト}}{\\mbox{最高の売上高}-\\mbox{最低の売上高}}, \\\\ &amp;\\mbox{固定費}=\\mbox{最高（最低）の売上高のときのコスト}-\\mbox{最高（最低）のときの売上高の変動費}, \\end{align*}\\] たとえば，自動車のドアを製造しているとある工場において，1月から6月について，コストと売上高に関して，次のような実績データが得られたとする。なお，1月から6月のいずれの売上高も正常な範囲内であるとする。コストと売上高の単位は億円とする。 Table 7.1: 売上高とコストのデータ 月 売上高 コスト 1月 300 16 2月 310 15 3月 450 17 4月 700 23 5月 650 20 6月 540 17 これから，最低の売上高は1月に実現し，最高の売上高は4月に実現している。また，それぞれコストは16億円と23.2億円である。したがって，高低点法によれば，変動費率および固定費は次のように計算される。 # 変動費率の計算 vr &lt;- (23 - 16) / (700 - 300) vr ## [1] 0.0175 # 最高の営業時の変動費 vc &lt;- vr * 700 vc ## [1] 12.25 # 固定費の計算 fc &lt;- 23.2 - vc fc ## [1] 10.95 つまり，変動費率は0.0175，固定費は10.95億円と計算できた。 ただし，後述する最小二乗法を含めた固変分解の方法は，それぞれ一長一短あり，普遍的に正しい方法ではないことに注意が必要である。固変分解をするには，それぞれの方法の特徴を理解した上で，適切に選択することが必要である。 7.1.3 CVP分析における仮定 CVP分析は実務的にも広く用いられている管理会計ツールであるが，その背後にはいくつかの仮定が置かれていることに注意する必要がある(高田 2018, 221)。 変動費と固定費の分解が正しく行われていること。 固定費は，ある期間一定であること。 一定期間の間，変動費率に変化がないこと。 製品構成に変化がないこと。 異常な費用や損失の発生がないこと。 もちろん，現実的にはこれらの仮定を全て満たすことは限りなく不可能に近いだろう。したがって，CVP分析に基づく予測や分析結果は必ずしも精度が高いとは限らないことを頭の片隅に置いておくことが重要である。 しかし，仮にそうであったとしても，CVP分析が一定の有用な情報内容を含んでいることやその簡便さから，実務的に普及しているのだろう。 7.2 最小二乗法を利用した固変分解 7.2.1 データの確認 最小二乗法による固変分解の説明をする前に，まず，本節で利用するデータを読み込み，その中身を確認する。 データはこれまで利用してきた「data.csv」を利用する。 まずは作業環境をリセットし，分析に必要なパッケージおよび，それぞれのデータを読み込んで，必要な変数を抜き出してみよう。 ここでは，売上高と販管費と業種に関する情報を抜き出す。 # 作業環境のリセット remove(list = ls(all = TRUE)) library(tidyverse) # データの読み込み df &lt;- read_csv(&quot;data.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) %&gt;% select( sales, sga, ind ) ## ## ─ Column specification ──────────────────────────── ## cols( ## id = col_double(), ## name = col_character(), ## sales = col_double(), ## cogs = col_double(), ## sga = col_double(), ## asset = col_double(), ## debt = col_double(), ## equity = col_double(), ## receivable = col_double(), ## inventory = col_double(), ## payable = col_double(), ## tax = col_double(), ## ind = col_character(), ## ope_inc = col_double(), ## roa = col_double(), ## margin = col_double(), ## turnover = col_double(), ## employees = col_double() ## ) それではまず，データの特徴を確認しおこう。 我々が今関心があるのは，売上高とコストの関係性である。 それらの関係性を視覚的にとらえるために，散布図を描いてみよう。 散布図を描くには，ggplot2パッケージのgeom_point()関数を利用すればよい。 # 販管費の散布図 g &lt;- df %&gt;% ggplot(aes(x = sales, y = sga)) + geom_point() g 散布図を確認すると，縦軸に「e」と表記されている。これは，指数を表すexponentialの頭文字のeである。 具体的には，1e+05であれば，\\(1*10^5=100000\\)を表すこととなる。 2e+05であれば，\\(2*10^5=200000\\)を表すこととなる。 余談ではあるが，この表記は数値が小さいときにも利用される。 たとえば，1e-5であれば，\\(1*10^-5=0.00001\\)を表すこととなる。 それでは，つぎに，それぞれの業種を区別するために，異なる色をつけて散布図を描いてみよう。 # 販管費の散布図（業種ごとの色付き） g &lt;- df %&gt;% ggplot(aes(x = sales, y = sga, color = ind)) + geom_point() g ggplot2では，facet_wrap()関数やfacet_grid()関数利用することで，条件ごとにグラフを出力することもできる。 ここではfacet_wrap()関数について説明する。 facet_wrap()関数では，facet_wrap(~ variable)と記述することによって，条件ごとにグラフを表示できる。 variableには条件となる変数を入れてやればよい。 それでは，先ほど作成したg(全体の散布図)に加える形で業種ごとの散布図を描いてみよう。 g + facet_wrap(~ ind) 散布図を確認すると，両業種ともに売上高と販管費には正の関係が見られそうである。 また，家電業界で非常に規模の大きなサンプルが入っていることが分かるものの，業種間の大きな違いは見られなさそうである。 統計分析において，こうした非常に大きな（または小さな）値の観測値は，除外されることがある。 通常，統計分析において利用されるサンプルは，分析において想定される母集団を適切に代表している必要がある。 そのため，異常な値はサンプルから除外されたり（trim：トリム），特定の値で置き換える（winsorize：ウィンザライズ）といった処理がなされる。 そこで，ここでは売上高とコストに関して，上限値から1%のサンプルを除外して分析を進めてみよう。 そのことによって，上図の異常な値はサンプルから除外されるはずである。 サンプルを除外するために，quantile()関数を用いて基準となる値を特定し33，filter()関数によってデータを絞り込む。まずは，売上高とコストに関して上限1%の値を特定し，それらの値以上の観測値をサンプルから除外する。 # 上限1％の値を特定する df %&gt;% summarise( sales_99 = quantile(sales, 0.99), sga_99 = quantile(sga, 0.99) ) ## # A tibble: 1 x 2 ## sales_99 sga_99 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1449800. 366996. # 上限10％以上の観測値を除外する df_1 &lt;- df %&gt;% filter( sales &lt; 1449799.52, sga &lt; 366995.58 ) 実際に，nrow()関数を利用して，除外前後のサンプルの行数を比較すると，1社減少していることがわかる。 nrow(df) - nrow(df_1) ## [1] 1 念の為，除外後の散布図を描くと，次のようになる。 先程の非常に大きな値を取る観測値が除外されていることを目視で確認しよう。 g &lt;- df_1 %&gt;% ggplot(aes(x = sales, y = sga, color = ind)) + geom_point() + facet_wrap(~ ind) g CVP分析では売上高とコストの関係性を捉える直線を求める。 たとえば，前節で述べた高低点法では最高の売上高と最低の売上高の2点を選び，その直線関係によって，コストと売上高の関係をとらえる。 他方，スキャッターチャート法では，与えられた散布図を見て目分量で直線を引く方法である。 これから説明する最小二乗法では，与えられたデータを利用して，数学的に最も当てはまりの良い直線を求める。 7.2.2 最小二乗法に関する予備知識 最小二乗法は様々な分野で利用される回帰分析における統計分析の方法の一種である。 回帰分析は，要因となる変数（説明変数）と結果となる変数（被説明変数）の関係性を探る。 CVP分析では，とくに，単回帰分析を固変分解に利用できる。 単回帰分析では，1つの説明変数が被説明変数に与える影響を分析する34。 ただし，細かい計算過程については，統計学や計量経済学のテキストを参照せよ。 ここでは，コストを被説明変数，売上高を説明変数とした単回帰分析を考える。 今，ある企業のコストと売上高の関係が次の直線で表されているとしよう。 なお，ここで，\\(y\\)はコスト，\\(x\\)は売上高，\\(i\\)は企業を表すと考える。 \\[\\begin{align} y_i = \\alpha + \\beta x_i. \\label{eq:6.2} \\end{align}\\] このとき，\\(y_i\\)は\\(\\alpha\\)(固定費)と\\(\\beta x_i\\)(変動費)によって完全に表現される。 もし仮に，全てのデータが一直線上に並んでいるような場合であれば，このようなコストと売上高の直線関係を考えることができる。 ただし，通常そのようなことはありえない。 なぜなら，売上高と固定費，変動費の関係は，工場内での作業効率や，為替や景気変動といった非常に様々な要因から影響を受ける。 したがって，現実に観察されるコストのデータは，必ずしも一直線上にあるとは限らず，むしろそうした直線からズレることが多い。 いま，このズレのことを\\(\\varepsilon_i\\)とすると，コストと売上高の関係を表す()式は次のように書き換えられる。 \\[\\begin{equation} y_i = \\alpha + \\beta x_i + \\varepsilon_i. \\label{eq:6.3} \\end{equation}\\] ここで，\\(\\varepsilon_i\\)は説明変数で説明しきれなかった部分をとらえている。 したがって，このズレが小さいほど，コストと売上高の関係性を表す式として望ましいことが直感的に理解できるだろう。 そこで，最小二乗法ではこのズレが最小となる直線を求める。 ()式を変形すると次のようになる。 \\[\\begin{align} \\varepsilon_i = y_i - \\alpha - \\beta x_i. \\label{eq:6.4} \\end{align}\\] 上述したように，最小二乗法では，この\\(\\varepsilon_i\\)を最小にする\\(\\alpha\\)と\\(\\beta\\)を導出する。 最も単純な方法では，すべての企業の\\(\\varepsilon_i\\)を足し合わせることが考えられる。 しかし，\\(\\varepsilon_i\\)は正の値と負の値の両方を取りうるので，相殺し合う可能性がある。 そこで，\\(\\Sigma (\\varepsilon_i)^2\\) を最小にすることによって，\\(\\alpha\\)と\\(\\beta\\)を導出する。 細かい計算過程については統計学のテキストに譲るとして，最終的に\\(\\alpha\\)と\\(\\beta\\)は次のように導出される。 \\[\\begin{align*} \\beta &amp;= \\frac{x \\mbox{と} y \\mbox{の共分散}}{x \\mbox{の分散}}, \\\\ \\alpha &amp;= \\bar{y} -\\beta \\bar{x}. \\end{align*}\\] ここで，\\(\\bar{y}\\)はコストの平均値，\\(\\bar{x}\\)は売上高の平均値を表す。 最小二乗法によって推定される\\(\\beta\\)は，回帰直線の傾きであり，\\(x\\)が1単位変化すると，\\(y\\)がどれだけ変化するかを表す。 すなわち，CVP関係としてとらえると，\\(\\beta\\)は変動費率を表す。 一方，\\(\\alpha\\)は回帰直線の切片であり，売上高が0であってもかかるコストを表していることから，固定費であると解釈できる。 7.2.3 最小二乗法の実践 それでは，販管費を最小二乗法によって，固変分解してみよう。最小二乗法はlm()関数を用いて行う。lm()関数では，以下のように記述をする。 lm( 被説明変数 ~ 説明変数, data） とすることで，係数の推定を行える。 今回は独立変数が1つだけの場合を扱っているが，独立変数が複数ある重回帰分析の場合には，独立変数を複数配置する。 特徴としては，被説明変数と説明変数が「~（チルダ）」で結ばれている点である。 説明変数が複数ある場合には，説明変数同士を「+」で結んでやればよい（詳しくは次章を参照されたい）。 販管費を最小二乗法によって固変分解をする際には，販管費が被説明変数，売上高が説明変数であると考えてやればよい。 # 販管費を用いたCVP分析 cvp &lt;- lm(sga ~ sales, data = df_1) cvp ## ## Call: ## lm(formula = sga ~ sales, data = df_1) ## ## Coefficients: ## (Intercept) sales ## -12338.7507 0.2506 出力された結果を確認すると，「Call」には推定された式が表示される。 「Coefficients」と書かれた部分に\\(\\alpha\\)や\\(\\beta\\)といった係数の推定値に関する情報が書かれている。 「(Intercept)」には定数項に対する推定値（すなわち，\\(\\alpha\\)の値）が，「sales」には売上高の係数に対する推定値（すなわち，\\(\\beta\\)の値）が記載されている。 それぞれの数値を確認すると，固定費は$-$12,340万円，変動費率は0.2506であることを示している。 このように最小二乗法を用いた固変分解では，固定費が負の値で推定されてしまうこともあるので注意が必要である。 データに異常な値が含まれていないかどうかや，データのサイズは十分な大きさかどうかを事前にチェックする必要があるだろう。 最小二乗法による推定値に関する統計的な情報は，summary()関数を利用することによって，確認できる。 summary()関数を利用すると，各係数の推定値が0と有意に異なるかどうかを確認できる。 今回はCVP分析における固変分解において回帰分析の手法を利用したが，回帰分析は一般には仮説検証の場面において利用されることが多い。 そのような場合には，統計量に関わる情報が非常に役に立つ。 summary(cvp) ## ## Call: ## lm(formula = sga ~ sales, data = df_1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -39956 -3989 4584 9808 23108 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -12338.75069 11224.30590 -1.099 0.289 ## sales 0.25065 0.02165 11.580 0.00000000703 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 18060 on 15 degrees of freedom ## Multiple R-squared: 0.8994, Adjusted R-squared: 0.8927 ## F-statistic: 134.1 on 1 and 15 DF, p-value: 0.000000007027 上から順に出力結果を確認すると，「Call」には先程と同じく推定された式が表示されている。 「Residuals」には残差35に関する情報が示されている。 「Coefficients」にも先程と同様に係数に関する情報が書かれている。 その中で，「Estimates」という列には係数に対する推定値が書かれている。 「Std. Error」という列には推定値の標準誤差が，「t value」という列には推定値のt値が，「Pr(&gt;|t|) 」という列には推定値のp値が記載されている。 また，一番右端の「\\(\\mbox{***}\\)」や「.」といった記号はp値がどの有意水準より小さいかを示している。 基準となる有意水準は「Signif. codes」という行に示されている。 これらの記号はそれぞれ，「\\(\\mbox{***}\\)」であればp値が0と0.001の間に，「\\(\\mbox{**}\\)」であればp値が0.001と0.01との間に，「\\(\\mbox{*}\\)」であればp値が0.01と0.05との間に，「.」であればp値が0.05と0.1の間に存在することを意味する。 何も記号がついていなければp値は0.1と1の間に存在する。 「(Intercept)」という行を確認すると，定数項に対する推定値（\\(\\alpha\\)の値）は10％の水準で有意であることが，また「sales」の行を確認すると，売上高に対する推定値（\\(\\beta\\)の値）は0.1％の水準で有意であることが分かる。 なお，残りの部分には，残差の標準誤差や自由度，決定係数，F検定に関する結果が示されている。 このようにsummary()関数には様々な情報が記載されているが，特定の情報のみを取り出すこともできる。 なお，たとえば係数や決定係数のみを出力したい場合には，「$」を利用してその中身のみを指定できる36。 summary(cvp)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -12338.7506905 11224.30589791 -1.099289 0.28897321910477 ## sales 0.2506499 0.02164582 11.579598 0.00000000702675 summary(cvp)$adj.r ## [1] 0.8926802 それではつづいて，業種ごとに固変分解を行ってみよう。 業種ごとに分析をするためには，それぞれの業種で回帰分析を実行することとなる。 一番シンプルな方法は，filter()関数でそれぞれの業種だけのサンプルを作成し，それぞれのサンプルで回帰分析を実行することであろう。 まずはサンプルを絞る。 df_ds &lt;- df_1 %&gt;% filter( ind == &quot;DrugStore&quot; ) df_er &lt;- df_1 %&gt;% filter( ind == &quot;ElectronicsRetail&quot; ) 回帰分析については先程定義した「cvp」を利用できる。 そのためにはupdate()関数を利用しよう。 update()関数では，回帰式の変数の一部のみを変更する場合や，適用するデータを変更する際などに利用できる関数である。 update()関数はつぎのように記述する。 update(元の回帰式を格納したオブジェクト,.~., 新たなデータ) まず，environmentにある元の回帰式を格納したオブジェクトを記述する。 つぎに「.~.」は回帰式の修正に利用する項目である。 「.」は元の回帰式の変数を意味している。 特に修正する必要がない場合には，この部分は省略しても構わない。 「~」は通常のlm関数のときと同様に，被説明変数と説明変数を結んでいる。 たとえば，被説明変数に新たに別のコストとして売上原価(cogs)を利用したければ，次のようにしてやればよい。 （ただし，ここで利用しているデータにはcogsという変数がないので下のコードは実際には機能しない） update(cvp, cogs ~ . , data = df_1) また，変数を追加する場合には「+」，変数を減らす場合には「-」というふうに記述する。 たとえば，説明変数に新たにgdpという変数を加えたければ， update(cvp, . ~ . + gdp , data = df_1) としてやればよい。 cvp_ds &lt;- update(cvp, data = df_ds) cvp_ds ## ## Call: ## lm(formula = sga ~ sales, data = df_ds) ## ## Coefficients: ## (Intercept) sales ## -23238.7204 0.2621 cvp_er &lt;- update(cvp, data = df_er) cvp_er ## ## Call: ## lm(formula = sga ~ sales, data = df_er) ## ## Coefficients: ## (Intercept) sales ## -395.8677 0.2423 分析の結果，ドラッグストア業界の固定費は$-\\(23,240百万円，変動費率は0.2621であることが分かる。 また，家電量販店業界の固定費は\\)-$395.8677百万円，変動費率は0.2423であることが分かる。 今回の例のように，最小二乗法による固変分解は万能ではなく，しばしば問題を伴う。 たとえば，変動費率が1を超えてしまうことや，固定費がしばしば負の値として推定される問題が指摘されているので注意してほしい(福嶋 and 新井 2012; 乙政 2014; 高田 2018)。 その理由としては，固定費が長期的には変動費化すること(Kaplan and Cooper 1987)，製品単位あたりの販売価格や変動費が一定であることや，在庫の存在が無視されるといったCVP分析の教科書的仮定からの逸脱，利益と関連する自由裁量費の存在(福嶋, 新井, and 松尾 2014)などが考えられる。 CVP分析を行う際には，上記の問題を理解した上で，分析してほしい。 以上が最小二乗法を用いた固変分解の方法となる。売上高に対するコスト関数を推定することで，損益分岐点分析なども行うことができるようになる。 興味がある読者は，一般的な原価計算や管理会計のテキストを参照していただきたい。 Volumeは厳密には，売上高に限定されるわけではなく，営業量や操業度を含む広い概念である。↩︎ コストを材料費，労務費，経費に分ける分類方法もある。詳しくは，原価計算のテキストを参照せよ。↩︎ quantile()関数では任意の分位数を計算できる。その計算のアルゴリズムには9つのタイプが用意されているので，コンソールに「?quantile」と打ち込んで確認してみよう。↩︎ 複数の説明変数を扱う回帰分析のことを重回帰分析と呼ぶが，その詳細については次章で説明する。↩︎ 残差とは，実際の観測値と推定された回帰式の基づく予測値の差を表す。回帰分析を学習する上では非常に重要な概念ではあるが，ここでは扱わない。興味のある読者は，統計学や計量経済学のテキストを参照せよ。↩︎ Rのコンソールに「?lm」や「?summary.lm」と入力し，それぞれの関数にどのような値が用意されているか確認してみよう。↩︎ "],["08-重回帰.html", "Chapter 8 コストビヘイビアを推定する 8.1 費用構造が変化した場合の費用直線の推定 8.2 コストドライバー分析", " Chapter 8 コストビヘイビアを推定する &lt;学習目標&gt; ・費用構造が変化した場合の変動費率・固定費を推定できる ・コスト・ドライバーの分析ができる 【応用例】 同じデータセット内で費用構造が異なる場合の費用直線の推定 コスト・ドライバー分析 【関連する会計研究】 Anderson, M. C., R. D. Banker, and S. N. Janakiraman (2003) “Are selling, general, and administrative costs”sticky“?” Journal of Accounting Research, Vol. 41, No. 1, pp. 47-63. 8.1 費用構造が変化した場合の費用直線の推定 8.1.1 ダミー変数 前章では，回帰分析によるCVP分析を学習した。CVP分析では，コストを変動費と固定費という2種類のコストに分類できると仮定することで，コストを売上高の変数として説明することができた。 また，このCVP分析を行うため，Rのlm()関数を用いて，会計数値から企業のコスト直線を推定した。 しかし，企業の費用直線を推定するうえで，この推定方法が常に適切とは限らない。 たとえば，下記のソフトバンクグループの売上高と営業費用（売上高-営業利益）のグラフをみてみよう。 データはソフトバンクグループのホームページから取得し，前章と同じように単回帰分析によって推定した費用直線の結果をggplotで可視化した。 なお，geom_abline()関数はggplotに斜線を追加する関数で，引数には傾き(slope)と切片(intercept)を指定する必要がある。 単回帰分析の斜線を書き込みたいので，単回帰分析の係数を取り出すcoef()関数を用いて，それぞれ単回帰分析により推定した傾きと切片を指定している。 # ライブラリの読み込み library(tidyverse) # データの読み込み df_0 &lt;- read_csv(&quot;softbank.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## Warning: Missing column names filled in: &#39;X1&#39; [1] ## ## ─ Column specification ──────────────────────────── ## cols( ## X1 = col_double(), ## fy = col_double(), ## sales = col_double(), ## cost = col_double() ## ) # 単回帰分析 lm_1 &lt;- lm(cost ~ sales, df_0) summary(lm_1) ## ## Call: ## lm(formula = cost ~ sales, data = df_0) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2095.6 -853.9 123.9 487.9 1624.7 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1769.09405 581.94742 3.04 0.0112 * ## sales 0.76058 0.02683 28.35 0.0000000000123 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1121 on 11 degrees of freedom ## Multiple R-squared: 0.9865, Adjusted R-squared: 0.9853 ## F-statistic: 803.6 on 1 and 11 DF, p-value: 0.00000000001234 g &lt;- ggplot(df_0, aes(x = sales, y = cost)) + geom_point() + geom_abline( slope = coef(lm_1)[2], intercept = coef(lm_1)[1] ) g 出力されたグラフをみると，データが明らかに2つのグループに分かれている。 なお，左下のグループが2005年以前のデータで，右上のグループが2006年以降のデータである。 これは，ソフトバンクグループが2006年にボーダフォンを買収したことによる影響だと考えられる。 ソフトバンクグループはボーダフォン買収により，新しくモバイル事業によるサービスを提供できるようになった。 ソフトバンクのようにコスト直線の推定に使用するデータ内で，企業のコスト構造が大きく変化している場合，変化前と変化後で異なるコスト直線を推定する必要がある。 データセットにOLSを適用し，直線を推定したいものの，同じデータセット内にある異なるグループごとに異なる直線を推定したい，という場面にはよく遭遇する。 たとえば，産業や上場時期ごとに異なるコスト直線を推定したいケースもなどである。 こうした状況で，データセットを分割することなく，各グループの直線を推定できる方法がダミー変数を用いた回帰分析である。 ダミー変数とは，「ある条件を満たせば1，そうでなければ0」をとる変数をさす。 ダミー変数をもちいることで，「製造業なら1，そうでなければ0」などのカテゴリーを表す表現も，数値に置き換えて回帰式に組み込むことができる。 ダミー変数の作成にはif_else()関数をもちいる。たとえば，「買収後のデータなら1，そうでなければ0」をとるダミー変数を作成したければ，下記のようなコードになる。 # ダミー変数の作成 df_0 &lt;- df_0 %&gt;% mutate( fy_dummy = if_else(fy &gt;= 2006, 1, 0) ) 8.1.2 グループごとに固定費のみを変えたい場合 それでは，作成したダミー変数を回帰式に組み込んでみよう。買収後に固定費が増加したと考える場合，次のような回帰式を推定すればよい。 【グループごとに固定費のみを変える回帰式】 \\[\\begin{align} Cost_t=\\beta_0 + \\beta_1 Sales_t + \\beta_2 Dummy_t +\\varepsilon_t. \\label{eq:8.1} \\end{align}\\] このように回帰式を定義しておけば，買収前のデータであれば「\\(Dummy=0\\)」となるので，下式Beforeのようになり\\(\\beta_0\\)が買収前の固定費を表す37。 一方，買収後のデータであれば「\\(Dummy=1\\)」となるので，下式Afterのようになり, 「\\(\\beta_0 +\\beta_2\\)」が買収後の固定費を表す。 すなわち，\\(\\beta_2\\)が買収によって増加した固定費を表す。 【買収前のデータに対する回帰式(Before)】 \\[\\begin{align} Cost_t=(\\beta_0 \\hspace{0.6cm}) + \\beta_1 Sales_t + \\varepsilon_t, \\label{eq:8.2} \\end{align}\\] 【買収後のデータに対する回帰式(After)】 \\[\\begin{align} Cost_t=(\\beta_0 +\\beta_2) + \\beta_1 Sales_t + \\varepsilon_t. \\label{eq:8.3} \\end{align}\\] それでは，実際にダミー変数をもちいた回帰分析を実行してみよう。 コードは下記のようになる。 なお，回帰分析結果のグラフを表示するコードも示している。 # 固定費のみダミー lm_2 &lt;- lm(cost ~ sales + fy_dummy, df_0) summary(lm_2) ## ## Call: ## lm(formula = cost ~ sales + fy_dummy, data = df_0) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1624.1 -741.5 -108.3 931.0 1341.6 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2732.5130 824.6320 3.314 0.007831 ** ## sales 0.5855 0.1149 5.094 0.000468 *** ## fy_dummy 4173.0534 2672.0017 1.562 0.149405 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1054 on 10 degrees of freedom ## Multiple R-squared: 0.9891, Adjusted R-squared: 0.987 ## F-statistic: 455.6 on 2 and 10 DF, p-value: 0.0000000001508 cc &lt;- tibble( sl = c(coef(lm_2)[2], coef(lm_2)[2]), int = c(coef(lm_2)[1], coef(lm_2)[1] + coef(lm_2)[3]), time_dummy = c(&quot;0&quot;, &quot;1&quot;) ) g &lt;- df_0 %&gt;% ggplot( aes( x = sales, y = cost, colour = as.character(fy_dummy) ) ) + geom_point() + geom_abline( data = cc, aes( slope = sl, intercept = int, colour = time_dummy ) ) g グラフをみると，同じ傾きの直線が2本表示されている。 下の回帰直線は買収前のデータに対する分析結果，そこから上に\\(\\beta_2\\)だけずれた回帰直線は買収後のデータに対する分析結果である。 このグラフの結果は買収によって，\\(\\beta_2\\)だけ固定費が上昇したことを表している。 ここで注意したいのは，回帰分析の結果が「買収前と買収後で回帰直線の傾きが同じである」と仮定したうえでの分析結果だということだ。 すなわち，買収前と買収後で変動費率も変化しているとも考えられるが，上記の固定費ダミーの数式では変動費率の変化を表現することができない。 しかし，この問題はダミー変数をちょっとだけ工夫して回帰分析に組み入れることで，簡単に解決できる。 8.1.3 グループごとに固定費および変動費率を変えたい場合 買収によって変動費率も変化したと考える場合，次のような回帰式を推定すればよい。 【グループごとに固定費および変動費率を変える回帰式】 \\[\\begin{eqnarray} Cost_t=\\beta_0 + \\beta_1 Sales_t + \\beta_2 Sales_t \\times Dummy_t + \\varepsilon_t. \\label{eq:8.4} \\end{eqnarray}\\] この回帰式では，買収前と買収後のデータに対する予測値がBeforeとAfterのように変化する。この式では，\\(\\beta_2\\)が買収による固定費の変化分を，\\(\\beta_3\\)が買収による変動費率の変化分を表している。 【買収前のデータに対する回帰式(Before)】 \\[\\begin{eqnarray} Cost_t=(\\beta_0 \\hspace{0.6cm}) +( \\beta_1 \\hspace{0.6cm} ) Sales_t+ \\varepsilon_t, \\label{eq:8.5} \\end{eqnarray}\\] 【買収後のデータに対する回帰式(After)】 \\[\\begin{eqnarray} Cost_t=(\\beta_0 +\\beta_2) + ( \\beta_1 +\\beta_3 ) Sales_t + \\varepsilon_t. \\label{eq:8.6} \\end{eqnarray}\\] それでは，コードを実行してみよう。 # 固定費と変動費率の両方をダミー lm_3 &lt;- lm(cost ~ sales + fy_dummy + sales:fy_dummy, df_0) summary(lm_3) ## ## Call: ## lm(formula = cost ~ sales + fy_dummy + sales:fy_dummy, data = df_0) ## ## Residuals: ## Min 1Q Median 3Q Max ## -608.5 -340.0 -154.0 318.2 990.9 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 904.65305 584.12642 1.549 0.155855 ## sales 0.88413 0.08733 10.124 0.00000323 *** ## fy_dummy 15300.51943 2688.48058 5.691 0.000298 *** ## sales:fy_dummy -0.62154 0.12598 -4.934 0.000809 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 577.4 on 9 degrees of freedom ## Multiple R-squared: 0.9971, Adjusted R-squared: 0.9961 ## F-statistic: 1021 on 3 and 9 DF, p-value: 0.00000000001031 cc &lt;- tibble( sl = c(coef(lm_3)[2], coef(lm_3)[2] + coef(lm_3)[4]), int = c(coef(lm_3)[1], coef(lm_3)[1] + coef(lm_3)[3]), time_dummy = c(&quot;0&quot;, &quot;1&quot;) ) g &lt;- df_0 %&gt;% ggplot( aes( x = sales, y = cost, colour = as.character(fy_dummy) ) ) + geom_point() + geom_abline( data = cc, aes( slope = sl, intercept = int, colour = time_dummy ) ) g 出力されたグラフをみてみると，買収前と買収後で固定費と変動費率の両方が変化していることをうまく表現できていることがわかる。 8.2 コストドライバー分析 8.2.1 重回帰分析 前節では，ダミー変数を用いることで同じデータセット内の異なるグループごとに異なる直線が推定できることを学習した。 コスト直線の推定式に買収ダミーを追加すれば，売上高とコストの関係を場合分けして分析できた。 また，追加した買収ダミーに対する係数は，買収によって変化した分の固定費・変動費率をそれぞれ表していた。 いいかえれば，回帰式に新しく変数を追加することで，買収時の経営者の意思決定がコストに与える影響を数式に反映させた。 このように，現実のコスト変動は複雑であるため，売上高という1変数ですべてを説明できるわけではない。 前節で示したように，コストは買収行動の結果など他の様々な影響も受ける。 もし，コストに追加的な影響を与える要因がYes/Noで答えられるような変数，すなわちカテゴリー変数であるならば，前節と同様にダミー変数を使えばよい。 しかし，コストに追加的な影響を与える要因が「取り扱っている製品の種類数」や「所属している従業員数」など連続値である場合はどうすればよいのか。 答えは，ダミー変数と同じように説明変数として回帰式に追加すればよい。 追加する変数がダミー変数であるか，連続値をとる変数かによらず，2つ以上（定数項を含めれば3つ以上）の変数を使用する回帰分析を一般に重回帰分析とよぶ。 本節では，重回帰分析の例として販売費及び一般管理費（以下，販管費）のコスト・ドライバー分析をあつかう。 ビジネスに関する費用は，商品の仕入れや製品の製造にかかった費用である売上原価と，広告宣伝費や研究開発などそれ以外の費用である販管費に大別される。 本節では，いわば「その他」の支出を表す販管費が，どのような要因によってどの程度増減しているのかを検証する。 販管費は費用の一区分なので，前節までの議論と同様に販管費を売上高の関数とみなすことができる。 すなわち，売上高が増加し営業量が増加するほど損益計算書に計上される販管費は増加すると考える。 ここまでなら，売上高を説明変数とする単回帰分析で十分だろう。 そこで，販管費に影響を与える追加変数として，今回は新しく「従業員数(employees)」という変数を考える。 販管費の大部分が人件費であることを考えれば，従業員数が増加することで販管費も増加すると考えられる。 従業員数のようにコストを増加させる要因のことをコスト・ドライバーと呼び，実際にコスト・ドライバーの増減によってコストが増減しているか検証する分析をコスト・ドライバー分析とよぶ。 ダミー変数と同じように，従業員数が販管費に与える影響もみたいなら，次のように回帰式へ変数として追加すればよい。 【重回帰分析の回帰式】 \\[\\begin{eqnarray} Cost_i=\\beta_0 +\\beta_1 Sales_i + \\beta_2 Employees_i+ \\varepsilon_i. \\label{eq:8.7} \\end{eqnarray}\\] 詳しい説明はあとに回すとして，コードを実行してみよう。 データはこれまでに利用した家電量販店とドラッグストアのデータを利用する。 下記のコードでは回帰分析の結果を見やすくするため，stargazerパッケージを使用した。 # 作業環境のリセット remove(list = ls(all = TRUE)) # 重回帰分析 df_0 &lt;- read_csv(&quot;data.csv&quot;, locale = locale(encoding = &quot;cp932&quot;) ) ## ## ─ Column specification ──────────────────────────── ## cols( ## id = col_double(), ## name = col_character(), ## sales = col_double(), ## cogs = col_double(), ## sga = col_double(), ## asset = col_double(), ## debt = col_double(), ## equity = col_double(), ## receivable = col_double(), ## inventory = col_double(), ## payable = col_double(), ## tax = col_double(), ## ind = col_character(), ## ope_inc = col_double(), ## roa = col_double(), ## margin = col_double(), ## turnover = col_double(), ## employees = col_double() ## ) # データチェック ggplot(df_0,aes(x=sales)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_0,aes(x=sga)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(df_0,aes(x=sales,y=sga)) + geom_point() # 異常値排除(ヤマダ電機) df_0 &lt;- df_0 %&gt;% filter(sales&lt;1000000) # 回帰分析 lm_simple &lt;- lm(sga ~ sales, df_0) lm_multi &lt;- lm(sga ~ sales + employees, df_0) # 結果を出力 # install.packages(&quot;stargazer&quot;) library(stargazer) ## ## Please cite as: ## Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables. ## R package version 5.2.2. https://CRAN.R-project.org/package=stargazer stargazer( lm_simple, lm_multi, type = &quot;latex&quot;, header = FALSE, float = FALSE ) データの単位は100万円である。 重回帰分析の結果を，単回帰分析の結果をみるときと同じ要領でみてみよう。 まず，売上高の係数は売上高が100万円上がると販管費が平均的に21.2万円上昇することを示している。 次に，従業員の係数は従業員数が1人増えると販管費が平均的に435.4万円上昇することを示している。 一方，単回帰分析の結果と比較してみると，重回帰分析における売上高の回帰係数は下がっている。 なぜ，従業員数を回帰式に追加した重回帰分析では，売上高の係数が下がるのだろうか。 この点について説明するために，残差を用いた回帰分析を実行してみよう。 8.2.2 残差回帰 重回帰分析と単回帰分析で売上高の係数が異なる理由は，売上高の変動パターンと従業員数の変動パターンの一部が重複しているからだ。 これは，両者の相関係数が0ではないことと同義である。 売上高と従業員数に相関があるのは直感的だろう。 売上高が高くなるとそれだけ従業員が必要になるし，逆もまたしかりである。 しかし，売上高に対してどれだけの従業員が必要となるかは企業によって異なる。 たとえば，同じ売上高だったとしても，製造業とサービス業とでは必要な従業員数が異なるだろう。 すなわち，従業員数の変動パターンと売上高の変動パターンは完全には一致せず，重複していない部分もある。 したがって，売上高と従業員数の相関係数は1より小さい。 両者の分析結果が異なるのは，単回帰分析では売上高の変動パターン全体が販管費をどの程度説明できるかを推定しているのに対し，重回帰分析では売上高の変動パターンのうち従業員数と重複していない部分が，販管費をどの程度説明できるかを推定しているためである。 この点について解説するため，以下の回帰式を推定してみよう。 【売上高に対する回帰式】 \\[\\begin{eqnarray} Sales_i=\\alpha_0 +\\alpha_1 Employees_i+ \\xi_i. \\label{eq:8.8} \\end{eqnarray}\\] コードは以下の通り。 # 残差回帰 # 売上高を従業員数で推定 lm_sales &lt;- lm(sales ~ employees, df_0) summary(lm_sales) ## ## Call: ## lm(formula = sales ~ employees, data = df_0) ## ## Residuals: ## Min 1Q Median 3Q Max ## -286568 -38689 8527 42456 205518 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 58288.43 79991.07 0.729 0.477 ## employees 76.43 13.55 5.640 0.0000471 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 122000 on 15 degrees of freedom ## Multiple R-squared: 0.6795, Adjusted R-squared: 0.6582 ## F-statistic: 31.8 on 1 and 15 DF, p-value: 0.00004707 上記のコードでは，売上高を被説明変数，従業員数を説明変数とした単回帰分析を行っている。 この分析の目的は，売上高の変動パターンを，従業員数の変動パターンで「説明できる部分」と「説明できない部分」に区分することにある。 すなわち，予測値(\\(\\alpha_0+ \\alpha_1 Employees_i\\))を「従業員数の変動パターンで説明できる部分」，残差(\\(\\xi_i\\))を「従業員数の変動パターンで説明できない部分」だと考えるのである。 売上高と従業員数の関係が単純な一次式の関係になっていると考えるのは難しいかもしれない。 しかし，ここは思い切って残差(\\(\\xi_i\\))が，従業員数の変動パターンでは説明できない売上高独自の変動を捉えていると仮定して話を進めることにしよう。 この売上高独自の変動を表す残差(\\(\\xi_i\\))は，販管費をどの程度説明するのだろうか。 実際に，コードを回して確認してみよう。 # 残差回帰と重回帰分析の比較 df_0 &lt;- df_0 %&gt;% mutate( estimate = coef(lm_sales)[1] + coef(lm_sales)[2] * employees, residuals = sales - estimate, ) lm_residual &lt;- lm(sga ~ estimate + residuals, df_0) stargazer( lm_simple, lm_multi, lm_residual, type = &quot;latex&quot;, header = FALSE, float = FALSE ) 出力された分析結果をみてみると，残差回帰での残差の回帰係数（0.212）と重回帰での売上高の回帰係数（0.212）が一致している。 この分析結果は偶然ではない。 重回帰分析の数学上の性質である。 重回帰分析における売上高の係数は，次のように解釈できる。 すなわち，重回帰分析における売上高の係数は，売上高独自の（従業員数の変動パターンと重複していない）変動パターンが販管費をどの程度説明できるかを表している。 反対に，売上高独自ではない（従業員数の変動パターンと重複した）変動パターンが販管費をどの程度説明できるかは，推定値（estimate）の回帰係数（0.269）で表される。 したがって，重回帰分析をもちいることで従業員数の影響を取り除いたうえで，なお売上高が販管費に対してどの程度の追加的な影響があるのか検証できる。 ただし，ここで「販管費に影響を与える」や「従業員数の影響を取り除いた」という表現には注意が必要である。 単回帰分析でも重回帰分析でも，両者はあくまで変数間の相関をみているにすぎない。 たとえば，従業員数の影響を取り除いたといっても，それはあくまで従業員数と相関する部分を回帰分析によって計算上取り除いた値にすぎない。 分析に利用していない，もしくは利用できないような変数が被説明変数および説明変数に影響を与えている場合などは，別の分析を必要がある。 Anderson, M. C., R. D. Banker, and S. N. Janakiraman. 2003. “Are Selling, General, and Administrative Costs \"Sticky\"?” Journal of Accounting Research 41 (1): 47–63. Anderson, S. W., and K. L. Sedatole. 2012. “Evidence on the Cost Hierarchy: The Association Between Resource Consumption and Production Activities.” Journal of Management Accounting Research 25 (1): 119–41. Banker, R. D., G. Potter, and R. G. Schroeder. 1995. “An Empirical Analysis of Manufacturing Overhead Cost Drivers.” Journal of Accounting and Economics 19 (1): 115–37. Burgstahler, D., and I. Dichev. 1997. “Earnings Management to Avoid Earnings Decreases and Losses.” Journal of Accounting and Economics 24 (1): 99–126. Ittner, C. D., and D. F. Larcker. 2005. “Moving from Strategic Measurement to Srategic Data Analysis.” In Control Strategy: Mamagement, Accounting and Performance Measurement, edited by C. Chapman, 86–105. Oxford University Press. Jones, J. J. 1991. “Earnings Management During Import Relief Investigations.” Journal of Accounting Research 29 (2): 193–228. Kaplan, R. S., and R. Cooper. 1987. “How Cost Accounting Systematically Distorts Product Costs.” In Accounting and Management: Field Study Perspectives, edited by W. J. Bruns and R. S. Kaplan, 204–28. Boston: Harvard Business School Press. Lander, J. P. 2017. R for Everyone: Advanced Analytics and Graphics (2nd Edition) (Addison-Wesley Data &amp; Analytics Series). Addison-Wesley Professional. Roychowdhury, S. 2006. “Earnings Management Through Real Activities Manipulation.” Journal of Accounting and Economics 42 (3): 335–70. Srivastava, A. 2014. “Why Have Measures of Earnings Quality Changed over Time?” Journal of Accounting and Economics 57 (2-3): 196–217. Wickham, H. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 1–23. 乙政正太. 2014. 財務諸表分析（第2版）. 同文館出版. 吉田栄介, 福島一矩, and 妹尾剛好. 2017. “わが国管理会計の実態調査：東証一部とその他上場企業との比較.” In 日本的管理会計の深層, edited by 吉田栄介, 49–80. 中央経済社. 國部克彦. 1994. アメリカ経営分析発達史. 白桃書房. 福嶋誠宣, and 新井康平. 2012. “企業レベルでのコストビヘイビア推定.” Hirao School of Management Review, no. 2: 1–7. 福嶋誠宣, 新井康平, and 松尾貴巳. 2014. “自由裁量費のコスト・ビヘイビアがCVP分析に与える影響 : 回帰分析による固定費推定の問題.” 会計プログレス, no. 15: 26–37. 舟尾暢男. 2009. The r Tips データ解析環境 r の基本技・グラフィックス活用集. 株式会社 オーム社. 高田直芳. 2018. ［決定版］ほんとうにわかる管理会計&amp;戦略会計. php出版. 単回帰分析で推定された費用直線の切片を固定費として解釈できるかどうかについては，前章でも述べたように多くの議論がある。たとえば，切片がマイナスで推定されてしまうこともあるため，切片を固定費と解釈することは難しいかもしれない。しかし，ここでは説明の都合上，費用直線の切片は固定費だと解釈して進めることにする。↩︎ "]]
